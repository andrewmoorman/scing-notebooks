{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, subprocess, boto3, json, shlex, mysql, os, urllib, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from s3path import S3Path\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from packaging import version\n",
    "pd.set_option(\"display.max_colwidth\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Priority of GEX data if multiple outputs are found in db\n",
    "sharp_wl_priority_map = {\n",
    "        m: [\"SEQC\", \"CR_GEX\"] for m in [\"Hashtag\", \"CiteSeq\"]\n",
    "    }\n",
    "# File patterns to search for in S3 for each accompanying pipeline\n",
    "sharp_wl_pattern_map = {\n",
    "    \"SEQC\": \"_dense.csv$\",\n",
    "    \"CR_GEX\": \"/filtered_feature_bc_matrix/barcodes.tsv.gz$\",\n",
    "    \"CR_ATAC\": \"/filtered_peak_bc_matrix/barcodes.tsv\"\n",
    "}\n",
    "sharp_wl_method_map = {\n",
    "    \"SEQC\": \"SeqcDenseCountsMatrixCsv\",\n",
    "    \"CR_GEX\": \"10x\",\n",
    "    \"CR_ATAC\": \"10x\",\n",
    "}\n",
    "# Names of FASTQ inputs in WDL; order is same as fastq_file_ids\n",
    "# TODO: Ask to change all inputs to \"fastq{file_id}\" or \"uriFastq{file_id}\"\n",
    "sharp_fastq_inputs_map = {\n",
    "    m: [\"uriFastqR1\", \"uriFastqR2\"] for m in [\"Hashtag\", \"CiteSeq\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTQ reads/indices required for each workflow\n",
    "fastq_map = {\n",
    "    'Hashtag': ['R1', 'R2'],\n",
    "    'CiteSeq': ['R1', 'R2'],\n",
    "    'AsapSeq': ['R1', 'R2', 'R3'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fastq file paths on S3 for each file id\n",
    "# Returns dictionary from id to s3 path\n",
    "# Throws exception if FASTQs don't exist for any id\n",
    "def get_fastqs(\n",
    "    path: str, # path to directory containing FASTQ files\n",
    "    fastq_file_ids: list, # FASTQ file ids needed for this run type (e.g. I1, R1, R2, etc.)\n",
    "):\n",
    "    fastq_map = dict()\n",
    "    _, bucket, key, _, _ = urllib.parse.urlsplit(path)\n",
    "    for fid in fastq_file_ids:\n",
    "        files = get_s3_objects(\n",
    "            bucket, key.lstrip(\"/\"),\n",
    "            re.compile(f\"_{fid}_\\d{{3}}.fastq.gz$\")\n",
    "        )\n",
    "        try:\n",
    "            assert files, f\"AssertionError: Missing `{fid}` archives!\"\n",
    "            fastq_map[fid] = [os.path.join(\"s3://\", bucket, str(f)) for f in files]\n",
    "        except AssertionError as err:\n",
    "            logging.warning(\"%s\\n\\t %s\", err, path)\n",
    "            return\n",
    "    return fastq_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get s3 path of existing GEX analysis files\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_wl_dir(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_stats_data = \"peer_lab_db.stats_data\"\n",
    "        table_stats_data = \"peer_lab_db.stats_data\"\n",
    "        table_hashtag_lib = \"peer_lab_db.hashtag_lib\"\n",
    "        table_genome_index = \"peer_lab_db.genome_index\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_stats_data}.analysis_storage\n",
    "        FROM {table_sample_data}\n",
    "        LEFT JOIN {table_stats_data} \n",
    "        ON {table_stats_data}.sampleData_id = {table_sample_data}.id\n",
    "        LEFT JOIN {table_hashtag_lib}\n",
    "        ON {table_hashtag_lib}.sampleData_id = {table_sample_data}.id\n",
    "        LEFT JOIN {table_genome_index}\n",
    "        ON {table_genome_index}.id = {table_hashtag_lib}.genomeIndex_id\n",
    "        LEFT JOIN {table_sc_tech}\n",
    "        ON {table_sc_tech}.id = {table_genome_index}.scTech_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        if result: \n",
    "            return result\n",
    "        # As backup, get AWS storage location directly from sample_data\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "            SELECT AWS_storage\n",
    "            FROM {table_sample_data}\n",
    "            WHERE {table_sample_data}.id = {sample_id}\n",
    "            \"\"\"\n",
    "            result = execute_query(query, user, password)[0][0]\n",
    "            return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get white list method and associated file\n",
    "# Throws exception if no white list exists\n",
    "def get_wl_params(\n",
    "    sample_id: str,\n",
    "    user: str,\n",
    "    password: str,\n",
    "):\n",
    "    wl_params = dict()\n",
    "\n",
    "    wl_dir = get_wl_dir(sample_id, user, password)\n",
    "    wl_patterns = [sharp_wl_pattern_map[p] for p in sharp_wl_priority_map[prefix]]\n",
    "\n",
    "    try:\n",
    "        # Check white list file exists before loading info from database\n",
    "        assert wl_dir, f\"Empty analysis storage for sample id {sample_id}\"\n",
    "        _, bucket, key, _, _ = urllib.parse.urlsplit(wl_dir)\n",
    "        # White list file and method is first entry found on S3 \n",
    "        wl = pd.DataFrame(\n",
    "            [get_s3_objects(bucket, key.strip(\"/\"), re.compile(p)) for p in wl_patterns],\n",
    "            index = sharp_wl_priority_map[prefix],\n",
    "        ).dropna(how=\"all\")\n",
    "        try:\n",
    "            wl_key = wl.iloc[0,0] # if empty, missing white list file\n",
    "            wl_params[\"uri\"] = os.path.join(\"s3://\", bucket, wl_key)\n",
    "            wl_params[\"method\"] = sharp_wl_method_map[wl.index[0]]\n",
    "        except IndexError:\n",
    "            logging.error(\n",
    "                \"Path to barcodes or counts matrix of GEX data is missing!\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "    except AssertionError:\n",
    "        logging.warning(f\"Path to GEX output results is missing for {sample_id}!\")\n",
    "        return\n",
    "\n",
    "    return wl_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bc_json_manual(\n",
    "    prefix,\n",
    "    platform,\n",
    "    user, \n",
    "    password,\n",
    "):\n",
    "    try:\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        query = f\"\"\"\n",
    "        SELECT barcodes\n",
    "        FROM {table_sc_tech}\n",
    "        WHERE {table_sc_tech}.sc_Tech = \"{platform.upper()}_{prefix}\"\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat barcodes from collaborator excel file\n",
    "def get_bcs_manual(\n",
    "    path_to_excel,\n",
    "):\n",
    "    # Replace unrecognized characters with text description\n",
    "    barcodes = pd.read_excel(path_to_excel) \n",
    "    replace = lambda x: x.encode('ascii', 'namereplace').decode().replace(\"\\\\N\", \"\")\n",
    "    barcodes[\"Description\"] = barcodes[\"Description\"].apply(replace)\n",
    "    barcodes[\"BP Shift\"] = 0\n",
    "    return barcodes[[\"Barcode\", \"DNA_ID\", \"Description\", \"BP Shift\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bc_params_manual(\n",
    "    barcodes,\n",
    "    prefix, \n",
    "    platform,\n",
    "    creds,\n",
    "):\n",
    "    bc_params = dict()\n",
    "    \n",
    "    # Add bp shift and sequence length based on conjugation\n",
    "    bp_shift_map = {\n",
    "        \"A\": 0,\n",
    "        \"B\": 10,\n",
    "        \"C\": 10,\n",
    "        \"M\": 1, # Methanol\n",
    "    }\n",
    "    conjugation = barcodes[\"DNA_ID\"].str.get(0)\n",
    "    if conjugation.nunique() != 1:\n",
    "        logging.warning(\n",
    "            f\"Sample has multiple hashtag barcode categories and will not be processed!\"\n",
    "        )\n",
    "        return\n",
    "    else:\n",
    "        bc_params[\"conjugation\"] = conjugation.values[0]\n",
    "        bc_params[\"bp_shift\"] = bp_shift_map[bc_params[\"conjugation\"]]\n",
    "        bc_params[\"seq_length\"] = bc_params[\"bp_shift\"] + barcodes[\"Barcode\"].apply(len).max()\n",
    "    \n",
    "    # JSON of bc and UMI positions are stored in database\n",
    "    bc_json = get_bc_json_manual(prefix, platform, creds['user'], creds['password'])\n",
    "    bc_pos = json.loads(bc_json)\n",
    "    bc_params[\"cb\"] = bc_pos[\"cellbarcode\"]\n",
    "    bc_params[\"umi\"] = bc_params[\"cb\"] + bc_pos[\"UMIs\"]\n",
    "    \n",
    "    return bc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template(\n",
    "    prefix: str, \n",
    "    conjugation: str = None,\n",
    "):\n",
    "    if prefix==\"Hashtag\":\n",
    "        return {\n",
    "            \"A\": \"hashtag-10x-v3-tsa\",\n",
    "            \"B\": \"hashtag-10x-v3-tsb\",\n",
    "            \"C\": \"hashtag-10x-tsc\",\n",
    "        }[conjugation]\n",
    "    elif prefix==\"CiteSeq\":\n",
    "        return \"citeseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy encoder for JSON from pandas series\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from SCRIdb\n",
    "def get_s3_objects(bucket, key, pattern, full_uri=False):\n",
    "    \n",
    "    s3r = boto3.resource(\"s3\")\n",
    "    bucket_s3 = s3r.Bucket(bucket)\n",
    "    objects = []\n",
    "    for obj in bucket_s3.objects.filter(Prefix=key):\n",
    "        hit = pattern.search(obj.key)\n",
    "        if hit:\n",
    "            objects.append(obj.key)\n",
    "    if full_uri:\n",
    "        objects = [f\"s3://{bucket}/{o}\" for o in objects]\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query, user, password):\n",
    "    with connect(\n",
    "        host=\"peer-lab-db.cggxmlwgzzpw.us-east-1.rds.amazonaws.com\",\n",
    "        database=\"peer_lab_db\",\n",
    "        user=user,\n",
    "        password=password,\n",
    "    ) as connection:\n",
    "        with connection.cursor(buffered=True) as cursor:\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_species(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_species = \"peer_lab_db.species\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_species}.Species\n",
    "        FROM {table_species}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_species}.id = {table_genome_idx}.species_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sc_tech(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sc_tech}.sc_Tech\n",
    "        FROM {table_sc_tech}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_sc_tech}.id = {table_genome_idx}.scTech_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sample_id(sample_name, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sample_data}.id\n",
    "        FROM {table_sample_data}\n",
    "        WHERE {table_sample_data}.Sample=\"{sample_name}\"\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_project_id(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_project_data = \"peer_lab_db.project_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_project_data}.projectName\n",
    "        FROM {table_project_data}\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_project_data}.id = {table_sample_data}.projectData_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SEQC_version(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 cp {loc}/seqc-results/seqc_log.txt -\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        version = re.match(r\".*SEQC=v(\\d+\\.\\d+\\.\\d+).*\", out)[1]\n",
    "        return version\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_prefix(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 ls {loc}/seqc-results/\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        \n",
    "        # Note: I'm expecting the aligned bam file to be in loc\n",
    "        bam_pattern = re.compile(r\"(.*)_Aligned\\.out\\.bam$\")\n",
    "        filename = list(filter(bam_pattern.match, out.split()))[0]\n",
    "        file_prefix = re.match(bam_pattern, filename)[1]\n",
    "        return file_prefix\n",
    "    except:\n",
    "        raise ValueError(f\"BAM file not found in {loc}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference(sample_id):\n",
    "    # Get species from database to decide reference\n",
    "    species = get_species(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"Human\" in species:\n",
    "        return \"s3://seqc-public/genomes/hg38_long_polya/annotations.gtf\"\n",
    "    elif \"Mouse\" in species:\n",
    "        return \"s3://seqc-public/genomes/mm38_long_polya/annotations.gtf\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Species: {species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bc_whitelist(sample_id):\n",
    "    # Get version from database to decide whitelist\n",
    "    sc_tech = get_sc_tech(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"V3\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v3/flat/3M-february-2018.txt\"\n",
    "    elif \"V2\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v2/flat/737K-august-2016.txt\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Technology: {sc_tech}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(\n",
    "    workflow_path: str,\n",
    "    execp: str,\n",
    "    secrets: str,\n",
    "    inputs: str,\n",
    "    labels: str,\n",
    "    options: str,\n",
    "):\n",
    "    # change working directory to the pipeline package\n",
    "    oldwd = os.getcwd()\n",
    "    os.chdir(workflow_path)\n",
    "    \n",
    "    # execute the pipeline command\n",
    "    cmd = f\"{workflow_path}/{execp} -k {secrets} -i {inputs} -l {labels} -o {options}\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)\n",
    "    out = var.__dict__\n",
    "    \n",
    "    # change working directory back\n",
    "    os.chdir(oldwd)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get bc and UMI positions from database stored in JSON format\n",
    "def get_bc_json(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_stats_data = \"peer_lab_db.stats_data\"\n",
    "        table_stats_data = \"peer_lab_db.stats_data\"\n",
    "        table_hashtag_lib = \"peer_lab_db.hashtag_lib\"\n",
    "        table_genome_index = \"peer_lab_db.genome_index\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        query = f\"\"\"\n",
    "        SELECT barcodes\n",
    "        FROM {table_sample_data}\n",
    "        LEFT JOIN {table_stats_data} \n",
    "        ON {table_stats_data}.sampleData_id = {table_sample_data}.id\n",
    "        LEFT JOIN {table_hashtag_lib}\n",
    "        ON {table_hashtag_lib}.sampleData_id = {table_sample_data}.id\n",
    "        LEFT JOIN {table_genome_index}\n",
    "        ON {table_genome_index}.id = {table_hashtag_lib}.genomeIndex_id\n",
    "        LEFT JOIN {table_sc_tech}\n",
    "        ON {table_sc_tech}.id = {table_genome_index}.scTech_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get bc sequence data from database\n",
    "def get_bcs(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_hashtag_barcodes = \"peer_lab_db.hashtag_barcodes\"\n",
    "        table_hashtags = \"peer_lab_db.hashtags\"\n",
    "        query = f\"\"\"\n",
    "        SELECT barcode_sequence, concat(substring(category, -1), barcode), \n",
    "        demultiplex_label, bp_shift FROM {table_hashtags} \n",
    "        LEFT JOIN {table_hashtag_barcodes} \n",
    "        ON {table_hashtag_barcodes}.id = {table_hashtags}.hashtagBarcodes_id \n",
    "        WHERE {table_hashtags}.sampleData_id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bc_params(\n",
    "    sample_id,\n",
    "    user,\n",
    "    password,\n",
    "):\n",
    "    bc_params = dict()\n",
    "\n",
    "    # JSON of bc and UMI positions are stored in database\n",
    "    # First check dense matrix exists before loading JSON from database\n",
    "    bc_json = get_bc_json(sample_id, user, password)\n",
    "    bc_pos = json.loads(bc_json)\n",
    "    bc_params[\"cb\"] = bc_pos[\"cellbarcode\"]\n",
    "    bc_params[\"umi\"] = bc_params[\"cb\"] + bc_pos[\"UMIs\"]\n",
    "\n",
    "    # Get bc sequence data from database\n",
    "    bcs = get_bcs(sample_id, user, password)\n",
    "    if not bcs:\n",
    "        logging.warning(f\"Barcodes data Empty:\\n\\t {db_connect.cur.statement}\")\n",
    "        return\n",
    "    for bc in bcs:\n",
    "        try:\n",
    "            assert bc[0], \"AssertionError: Missing sequence barcodes!\"\n",
    "            assert bc[1], \"AssertionError: Missing barcode IDs\"\n",
    "        except AssertionError as err:\n",
    "            logging.warning(f\"{err}:\\n\\t {db_connect.cur.statement}\")\n",
    "            return\n",
    "\n",
    "    barcodes = pd.DataFrame(bcs, columns=[\"sequence\", \"code\", \"label\", \"bp_shift\"])\n",
    "    conjugation = barcodes[\"code\"].str.get(0)\n",
    "    if conjugation.nunique() != 1:\n",
    "        logging.warning(\n",
    "            f\"Sample has multiple hashtag barcode categories and will not be processed!\"\n",
    "        )\n",
    "        return\n",
    "    else:\n",
    "        bc_params[\"conjugation\"] = conjugation.values[0]\n",
    "\n",
    "    if barcodes[\"bp_shift\"].nunique() != 1:\n",
    "        logging.warning(\n",
    "            f\"Sample {sample_id} has hashtag barcode categories, with bp-shift length/s \"\n",
    "            f\"{barcodes['bp_shift'].unique()}, and will not be processed!\"\n",
    "        )\n",
    "        return\n",
    "    else: \n",
    "        bc_params[\"bp_shift\"] = int(barcodes[\"bp_shift\"][0])\n",
    "        bc_params[\"seq_length\"] = bc_params[\"bp_shift\"] + barcodes[\"sequence\"].apply(len).max()\n",
    "\n",
    "    return bc_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps from .wdl name (prefix) to results dirname\n",
    "results_dirs = {\n",
    "    \"Hashtag\": \"Hashtag-results\",\n",
    "    \"CiteSeq\": \"CiteSeq-results\",\n",
    "}\n",
    "\n",
    "# Maps from .wdl name (prefix) to shell script\n",
    "sh_files = {\n",
    "    \"Hashtag\": \"submit-hashtag.sh\",\n",
    "    \"CiteSeq\": \"submit-citeseq.sh\",\n",
    "}\n",
    "\n",
    "# Maps from .wdl name (prefix) to pipeline name\n",
    "pipeline_types = {\n",
    "    \"Hashtag\": \"Hashtag\",\n",
    "    \"CiteSeq\": \"CITE-seq\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of docker files\n",
    "common_docker_registry = \"quay.io/hisplan\"\n",
    "\n",
    "prefix = \"Hashtag\" # Workflow(s) to run; also .wdl filename prefix(es)\n",
    "pipeline_type = pipeline_types[prefix] # field in *.labels.json\n",
    "output_dirname = results_dirs[prefix]\n",
    "\n",
    "# If need to add comment, put here\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharp-specific parameters\n",
    "options_prefix=\"Sharp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of workflow-related directories and files\n",
    "path_to_cromwell_secrets = f\"{Path.home()}/.cromwell/cromwell-secrets.json\" # CHANGE THIS\n",
    "workflow_dir = f\"{Path.home()}/scing/bin/sharp-0.0.13\" # CHANGE THIS\n",
    "path_to_exec = sh_files[prefix]\n",
    "config_dir = f\"{workflow_dir}/configs\"\n",
    "path_to_options = f\"{workflow_dir}/{options_prefix}.options.aws.json\"\n",
    "\n",
    "# Other file locations\n",
    "db_credentials_path = f\"{Path.home()}/.config.json\" # CHANGE THIS\n",
    "barcodes_path = f\"{Path.home()}/scing/data/barcodes\" # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials based on SCRIdb CLI config file\n",
    "with open(db_credentials_path) as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples on which to run Sharp\n",
    "# Notes: \n",
    "# - Assumes data is transferred to AWS s3 (this should be an s3 location)\n",
    "# - Assumes directory name is also name of sample\n",
    "# - Workflows above will be run on all samples below\n",
    "sample_paths = [\n",
    "    \"s3://dp-lab-data/collaborators/sunj/CdSgVdj001/ES-1428_MCMV_1_d7_CITE\",\n",
    "    \"s3://dp-lab-data/collaborators/sunj/CdSgVdj001/ES-1506_MCMV_D21_CITE\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method 1: From SCRIdb (Not Finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information for all samples\n",
    "sample_paths = [s.strip('/') for s in sample_paths] # remove trailing slash if exists\n",
    "sample_names = [os.path.basename(s) for s in sample_paths]\n",
    "sample_names = [re.match(r'(.*)_.+$', s)[1] for s in sample_names] # remove library suffix (e.g. _CITE, _HTO, etc.)\n",
    "# TODO: assert basename is in peer_lab_db.sample_data.Sample\n",
    "# assert(all(check_sample_name(s) for s in sample_names))\n",
    "samples = pd.DataFrame(\n",
    "    sample_paths,\n",
    "    index=sample_names,\n",
    "    columns=[\"S3_Path\"],\n",
    "    dtype=str,\n",
    ")\n",
    "# Get FASTQ paths from S3\n",
    "# Note: Uses same FASTQ file ids for all samples\n",
    "fastq_file_ids = fastq_map[prefix]\n",
    "samples[\"FASTQs\"] = samples[\"S3_Path\"].apply(lambda x: get_fastqs(x, fastq_file_ids))\n",
    "\n",
    "samples[\"Sample_ID\"] = pd.Series(samples.index).apply(\n",
    "    lambda x: get_sample_id(x, creds['user'], creds['password'])\n",
    ").values\n",
    "samples[\"Whitelist_Params\"] = samples['Sample_ID'].apply(\n",
    "    lambda x: get_wl_params(x, creds['user'], creds['password'])\n",
    ")\n",
    "samples[\"Barcode_Params\"] = samples['Sample_ID'].apply(\n",
    "    lambda x: get_bc_params(x, creds['user'], creds['password'])\n",
    ")\n",
    "samples[\"Barcodes\"] = samples['Sample_ID'].apply(\n",
    "    lambda x: get_bcs(x, creds['user'], creds['password'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S3_Path</th>\n",
       "      <th>FASTQs</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Whitelist_Params</th>\n",
       "      <th>Barcode_Params</th>\n",
       "      <th>Barcodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ES-1428_MCMV_1_d7</th>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>{'R1': ['s3://dp-lab-data/collaborat...</td>\n",
       "      <td>3560</td>\n",
       "      <td>{'uri': 's3://dp-lab-data/collaborat...</td>\n",
       "      <td>{'cb': 16, 'umi': 26, 'conjugation':...</td>\n",
       "      <td>[(ACCCACCAGTAAGAC, C0301, MCMV_1_D7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES-1506_MCMV_D21</th>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>{'R1': ['s3://dp-lab-data/collaborat...</td>\n",
       "      <td>3562</td>\n",
       "      <td>{'uri': 's3://dp-lab-data/collaborat...</td>\n",
       "      <td>{'cb': 16, 'umi': 26, 'conjugation':...</td>\n",
       "      <td>[(ACCCACCAGTAAGAC, C0301, MCMV_1_D21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   S3_Path  \\\n",
       "ES-1428_MCMV_1_d7  s3://dp-lab-data/collaborators/sunj/...   \n",
       "ES-1506_MCMV_D21   s3://dp-lab-data/collaborators/sunj/...   \n",
       "\n",
       "                                                    FASTQs  Sample_ID  \\\n",
       "ES-1428_MCMV_1_d7  {'R1': ['s3://dp-lab-data/collaborat...       3560   \n",
       "ES-1506_MCMV_D21   {'R1': ['s3://dp-lab-data/collaborat...       3562   \n",
       "\n",
       "                                          Whitelist_Params  \\\n",
       "ES-1428_MCMV_1_d7  {'uri': 's3://dp-lab-data/collaborat...   \n",
       "ES-1506_MCMV_D21   {'uri': 's3://dp-lab-data/collaborat...   \n",
       "\n",
       "                                            Barcode_Params  \\\n",
       "ES-1428_MCMV_1_d7  {'cb': 16, 'umi': 26, 'conjugation':...   \n",
       "ES-1506_MCMV_D21   {'cb': 16, 'umi': 26, 'conjugation':...   \n",
       "\n",
       "                                                  Barcodes  \n",
       "ES-1428_MCMV_1_d7  [(ACCCACCAGTAAGAC, C0301, MCMV_1_D7,...  \n",
       "ES-1506_MCMV_D21   [(ACCCACCAGTAAGAC, C0301, MCMV_1_D21...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462c791c36a1409798076303f70695a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to reformat barcode labels for Sharp\n",
    "def reformat_bc_label(label):\n",
    "    label = label.encode('ascii', 'namereplace').decode()\n",
    "    label = label.replace(\"\\\\N\", \"\").replace(\" \", \"_\")\n",
    "    return label\n",
    "\n",
    "for name, sample in tqdm(samples.iterrows(), total=len(samples)):\n",
    "    \n",
    "    # Reformat barcodes\n",
    "    barcodes = pd.DataFrame(\n",
    "        sample[\"Barcodes\"],\n",
    "        columns=[\"sequence\", \"code\", \"label\", \"bp_shift\"]\n",
    "    )\n",
    "    barcodes[\"label\"] = barcodes[\"label\"].apply(reformat_bc_label)\n",
    "    \n",
    "    # Save to CSV\n",
    "    path_to_csv = f\"{barcodes_path}/{sample['Sample_ID']}_tag-list.csv\"\n",
    "    barcodes.to_csv(path_to_csv, header=False, index=False)\n",
    "    \n",
    "    # Upload tag-list to AWS\n",
    "    cmd = f\"aws s3 cp {path_to_csv} {sample['S3_Path']}/{output_dirname}/tag-list.csv\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum inputs and labels fields from templates\n",
    "conjugation = samples[\"Barcode_Params\"].apply(lambda x: x[\"conjugation\"]).values[0] # conjugation must be same for all samples\n",
    "template_prefix = get_template(prefix, conjugation)\n",
    "with open(f\"{config_dir}/{template_prefix}.inputs.json\") as f:\n",
    "    std_inputs_fields = list(json.load(f).keys())\n",
    "    \n",
    "with open(f\"{config_dir}/{template_prefix}.labels.json\") as f:\n",
    "    std_labels_fields = list(json.load(f).keys())\n",
    "    \n",
    "# Annotate all samples with workflow inputs and labels\n",
    "inputs = pd.DataFrame(index=samples.index, columns=std_inputs_fields,)\n",
    "labels = pd.DataFrame(index=samples.index, columns=std_labels_fields,)\n",
    "\n",
    "platform = \"10x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate inputs\n",
    "inputs[f\"{prefix}.sampleName\"] = inputs.index\n",
    "inputs[f\"{prefix}.scRnaSeqPlatform\"] = platform # may need to change\n",
    "inputs[f\"{prefix}.lengthR1\"] = samples[\"Barcode_Params\"].apply(lambda x: x[\"umi\"])\n",
    "inputs[f\"{prefix}.lengthR2\"] = samples[\"Barcode_Params\"].apply(lambda x: x[\"seq_length\"])\n",
    "inputs[f\"{prefix}.cellBarcodeWhitelistUri\"] = samples[\"Whitelist_Params\"].apply(lambda x: x[\"uri\"])\n",
    "inputs[f\"{prefix}.cellBarcodeWhiteListMethod\"] = samples[\"Whitelist_Params\"].apply(lambda x: x[\"method\"])\n",
    "inputs[f\"{prefix}.{'tagList' if (prefix=='CiteSeq') else 'hashTagList'}\"] = \\\n",
    "    samples[\"S3_Path\"] + f\"/{output_dirname}/tag-list.csv\" #TODO: Ask about changing all to 'tagList'\n",
    "inputs[f\"{prefix}.cbStartPos\"] = 1\n",
    "inputs[f\"{prefix}.cbEndPos\"] = samples[\"Barcode_Params\"].apply(lambda x: x[\"cb\"])\n",
    "inputs[f\"{prefix}.umiStartPos\"] = inputs[f\"{prefix}.cbEndPos\"]+1\n",
    "inputs[f\"{prefix}.umiEndPos\"] = samples[\"Barcode_Params\"].apply(lambda x: x[\"umi\"])\n",
    "inputs[f\"{prefix}.trimPos\"] = samples[\"Barcode_Params\"].apply(lambda x: x[\"bp_shift\"])\n",
    "inputs[f\"{prefix}.translate10XBarcodes\"] = \\\n",
    "    (inputs[f\"{prefix}.scRnaSeqPlatform\"] == \"10x_v3\") & \\\n",
    "    (samples[\"Barcode_Params\"].apply(lambda x: x[\"conjugation\"] == \"B\"))\n",
    "inputs[f\"{prefix}.dockerRegistry\"] = common_docker_registry\n",
    "for file_id in fastq_file_ids: # Set FASTQs\n",
    "    inputs[f\"{prefix}.uriFastq{file_id}\"] = samples[\"FASTQs\"].apply(lambda x: x[file_id])\n",
    "\n",
    "# ********************\n",
    "# Defaults\n",
    "# Note: These may need to be changed on a per-sample or per-execution basis\n",
    "\n",
    "inputs[f\"{prefix}.slidingWindowSearch\"] = False\n",
    "inputs[f\"{prefix}.cbCollapsingDistance\"] = 1\n",
    "inputs[f\"{prefix}.umiCollapsingDistance\"] = 1\n",
    "inputs[f\"{prefix}.numExpectedCells\"] = 0\n",
    "# Need trick to set dictionary for each row\n",
    "common_resource_spec = {\n",
    "    \"cpu\": 32,\n",
    "    \"memory\": -1,\n",
    "}\n",
    "inputs[f\"{prefix}.resourceSpec\"] = inputs.iloc[:, 0].apply(lambda x: common_resource_spec)\n",
    "if prefix == \"Hashtag\":\n",
    "    inputs[f\"{prefix}.minCount\"] = 10\n",
    "\n",
    "# ********************\n",
    "\n",
    "# Annotate labels\n",
    "labels[\"pipelineType\"] = pipeline_type\n",
    "labels[\"project\"] = samples[\"Sample_ID\"].apply(lambda x: get_project_id(x, creds[\"user\"], creds[\"password\"]))\n",
    "labels[\"sample\"] = labels.index\n",
    "labels[\"owner\"] = creds[\"user\"]\n",
    "labels[\"destination\"] = samples['S3_Path'] + \"/\" + output_dirname\n",
    "labels[\"transfer\"] = \"-\"\n",
    "labels[\"comment\"] = creds[\"user\"]\n",
    "\n",
    "assert (std_inputs_fields == list(inputs.columns)) & (inputs.notna().values.all())\n",
    "assert (std_labels_fields == list(labels.columns)) & (labels.notna().values.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag.uriFastqR1</th>\n",
       "      <th>Hashtag.uriFastqR2</th>\n",
       "      <th>Hashtag.sampleName</th>\n",
       "      <th>Hashtag.scRnaSeqPlatform</th>\n",
       "      <th>Hashtag.lengthR1</th>\n",
       "      <th>Hashtag.lengthR2</th>\n",
       "      <th>Hashtag.cellBarcodeWhitelistUri</th>\n",
       "      <th>Hashtag.cellBarcodeWhiteListMethod</th>\n",
       "      <th>Hashtag.hashTagList</th>\n",
       "      <th>Hashtag.cbStartPos</th>\n",
       "      <th>...</th>\n",
       "      <th>Hashtag.umiEndPos</th>\n",
       "      <th>Hashtag.trimPos</th>\n",
       "      <th>Hashtag.slidingWindowSearch</th>\n",
       "      <th>Hashtag.translate10XBarcodes</th>\n",
       "      <th>Hashtag.cbCollapsingDistance</th>\n",
       "      <th>Hashtag.umiCollapsingDistance</th>\n",
       "      <th>Hashtag.numExpectedCells</th>\n",
       "      <th>Hashtag.minCount</th>\n",
       "      <th>Hashtag.resourceSpec</th>\n",
       "      <th>Hashtag.dockerRegistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ES-1428_MCMV_1_d7</th>\n",
       "      <td>[s3://dp-lab-data/collaborators/sunj...</td>\n",
       "      <td>[s3://dp-lab-data/collaborators/sunj...</td>\n",
       "      <td>ES-1428_MCMV_1_d7</td>\n",
       "      <td>10x</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>10x</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'cpu': 32, 'memory': -1}</td>\n",
       "      <td>quay.io/hisplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES-1506_MCMV_D21</th>\n",
       "      <td>[s3://dp-lab-data/collaborators/sunj...</td>\n",
       "      <td>[s3://dp-lab-data/collaborators/sunj...</td>\n",
       "      <td>ES-1506_MCMV_D21</td>\n",
       "      <td>10x</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>10x</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'cpu': 32, 'memory': -1}</td>\n",
       "      <td>quay.io/hisplan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Hashtag.uriFastqR1  \\\n",
       "ES-1428_MCMV_1_d7  [s3://dp-lab-data/collaborators/sunj...   \n",
       "ES-1506_MCMV_D21   [s3://dp-lab-data/collaborators/sunj...   \n",
       "\n",
       "                                        Hashtag.uriFastqR2 Hashtag.sampleName  \\\n",
       "ES-1428_MCMV_1_d7  [s3://dp-lab-data/collaborators/sunj...  ES-1428_MCMV_1_d7   \n",
       "ES-1506_MCMV_D21   [s3://dp-lab-data/collaborators/sunj...   ES-1506_MCMV_D21   \n",
       "\n",
       "                  Hashtag.scRnaSeqPlatform  Hashtag.lengthR1  \\\n",
       "ES-1428_MCMV_1_d7                      10x                26   \n",
       "ES-1506_MCMV_D21                       10x                26   \n",
       "\n",
       "                   Hashtag.lengthR2          Hashtag.cellBarcodeWhitelistUri  \\\n",
       "ES-1428_MCMV_1_d7                25  s3://dp-lab-data/collaborators/sunj/...   \n",
       "ES-1506_MCMV_D21                 25  s3://dp-lab-data/collaborators/sunj/...   \n",
       "\n",
       "                  Hashtag.cellBarcodeWhiteListMethod  \\\n",
       "ES-1428_MCMV_1_d7                                10x   \n",
       "ES-1506_MCMV_D21                                 10x   \n",
       "\n",
       "                                       Hashtag.hashTagList  \\\n",
       "ES-1428_MCMV_1_d7  s3://dp-lab-data/collaborators/sunj/...   \n",
       "ES-1506_MCMV_D21   s3://dp-lab-data/collaborators/sunj/...   \n",
       "\n",
       "                   Hashtag.cbStartPos  ...  Hashtag.umiEndPos  \\\n",
       "ES-1428_MCMV_1_d7                   1  ...                 26   \n",
       "ES-1506_MCMV_D21                    1  ...                 26   \n",
       "\n",
       "                   Hashtag.trimPos  Hashtag.slidingWindowSearch  \\\n",
       "ES-1428_MCMV_1_d7               10                        False   \n",
       "ES-1506_MCMV_D21                10                        False   \n",
       "\n",
       "                   Hashtag.translate10XBarcodes  Hashtag.cbCollapsingDistance  \\\n",
       "ES-1428_MCMV_1_d7                         False                             1   \n",
       "ES-1506_MCMV_D21                          False                             1   \n",
       "\n",
       "                   Hashtag.umiCollapsingDistance  Hashtag.numExpectedCells  \\\n",
       "ES-1428_MCMV_1_d7                              1                         0   \n",
       "ES-1506_MCMV_D21                               1                         0   \n",
       "\n",
       "                   Hashtag.minCount       Hashtag.resourceSpec  \\\n",
       "ES-1428_MCMV_1_d7                10  {'cpu': 32, 'memory': -1}   \n",
       "ES-1506_MCMV_D21                 10  {'cpu': 32, 'memory': -1}   \n",
       "\n",
       "                   Hashtag.dockerRegistry  \n",
       "ES-1428_MCMV_1_d7         quay.io/hisplan  \n",
       "ES-1506_MCMV_D21          quay.io/hisplan  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>project</th>\n",
       "      <th>sample</th>\n",
       "      <th>owner</th>\n",
       "      <th>destination</th>\n",
       "      <th>transfer</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ES-1428_MCMV_1_d7</th>\n",
       "      <td>Hashtag</td>\n",
       "      <td>CD_SG_VDJ_001</td>\n",
       "      <td>ES-1428_MCMV_1_d7</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES-1506_MCMV_D21</th>\n",
       "      <td>Hashtag</td>\n",
       "      <td>CD_SG_VDJ_001</td>\n",
       "      <td>ES-1506_MCMV_D21</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/collaborators/sunj/...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pipelineType        project             sample     owner  \\\n",
       "ES-1428_MCMV_1_d7      Hashtag  CD_SG_VDJ_001  ES-1428_MCMV_1_d7  moormana   \n",
       "ES-1506_MCMV_D21       Hashtag  CD_SG_VDJ_001   ES-1506_MCMV_D21  moormana   \n",
       "\n",
       "                                               destination transfer   comment  \n",
       "ES-1428_MCMV_1_d7  s3://dp-lab-data/collaborators/sunj/...        -  moormana  \n",
       "ES-1506_MCMV_D21   s3://dp-lab-data/collaborators/sunj/...        -  moormana  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232e9479dbfa4f8e9d0ee0b0f39b62c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdouts = [] # to store all outputs\n",
    "process = True\n",
    "\n",
    "with tqdm(samples.index) as t:\n",
    "\n",
    "    for sample_name in t:\n",
    "\n",
    "        # Write inputs and labels to file\n",
    "        path_to_inputs = f\"{config_dir}/{sample_name}_{prefix}.inputs.json\"\n",
    "        with open(path_to_inputs, \"w\") as f_inputs:\n",
    "            json.dump(inputs.loc[sample_name].to_dict(), f_inputs, indent=4, cls=NpEncoder)\n",
    "\n",
    "        path_to_labels = f\"{config_dir}/{sample_name}_{prefix}.labels.json\"\n",
    "        with open(path_to_labels, \"w\") as f_labels:\n",
    "            json.dump(labels.loc[sample_name].to_dict(), f_labels, indent=4, cls=NpEncoder)\n",
    "\n",
    "        if process:\n",
    "            stdouts.append(run(\n",
    "                workflow_path = workflow_dir,\n",
    "                execp = path_to_exec,\n",
    "                secrets = path_to_cromwell_secrets,\n",
    "                inputs = path_to_inputs,\n",
    "                labels = path_to_labels,\n",
    "                options = path_to_options,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': ['/Users/moormana/scing/bin/sharp-0.0.13/submit-hashtag.sh',\n",
       "   '-k',\n",
       "   '/Users/moormana/.cromwell/cromwell-secrets.json',\n",
       "   '-i',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/ES-1428_MCMV_1_d7_Hashtag.inputs.json',\n",
       "   '-l',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/ES-1428_MCMV_1_d7_Hashtag.labels.json',\n",
       "   '-o',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/Sharp.options.aws.json'],\n",
       "  'returncode': 0,\n",
       "  'stdout': '{\"id\":\"85177e58-f933-4718-9796-03b592de7c6c\",\"status\":\"Submitted\"}\\n',\n",
       "  'stderr': ''},\n",
       " {'args': ['/Users/moormana/scing/bin/sharp-0.0.13/submit-hashtag.sh',\n",
       "   '-k',\n",
       "   '/Users/moormana/.cromwell/cromwell-secrets.json',\n",
       "   '-i',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/ES-1506_MCMV_D21_Hashtag.inputs.json',\n",
       "   '-l',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/ES-1506_MCMV_D21_Hashtag.labels.json',\n",
       "   '-o',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/Sharp.options.aws.json'],\n",
       "  'returncode': 0,\n",
       "  'stdout': '{\"id\":\"a577fc96-cbea-4118-b938-95f4aee930d1\",\"status\":\"Submitted\"}\\n',\n",
       "  'stderr': ''}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Method 2: From Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual inputs\n",
    "platform = \"10x_v3\"\n",
    "#path_to_excel = f\"{Path.home()}/scing/barcodes/JR-1217_3080_Barcodes.xlsx\" \n",
    "path_to_excel = f\"{Path.home()}/scing/barcodes/3213_IM-1356.xlsx\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information for all samples\n",
    "sample_paths = [s.strip('/') for s in sample_paths] # remove trailing slash if exists\n",
    "sample_names = [os.path.basename(s) for s in sample_paths]\n",
    "sample_names = [re.match(r'(.*)_.+$', s)[1] for s in sample_names] # remove library suffix (e.g. _CITE, _HTO, etc.)\n",
    "# TODO: assert basename is in peer_lab_db.sample_data.Sample\n",
    "# assert(all(check_sample_name(s) for s in sample_names))\n",
    "samples = pd.DataFrame(\n",
    "    sample_paths,\n",
    "    index=sample_names,\n",
    "    columns=[\"S3_Path\"],\n",
    "    dtype=str,\n",
    ")\n",
    "samples[\"Sample_ID\"] = pd.Series(samples.index).apply(\n",
    "    lambda x: get_sample_id(x, creds['user'], creds['password'])\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S3_Path</th>\n",
       "      <th>Sample_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BF-1402_SI</th>\n",
       "      <td>s3://dp-lab-data/collaborators/arude...</td>\n",
       "      <td>3555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BF-1472_LI</th>\n",
       "      <td>s3://dp-lab-data/collaborators/arude...</td>\n",
       "      <td>3571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD-1495_1</th>\n",
       "      <td>s3://dp-lab-data/collaborators/arude...</td>\n",
       "      <td>3557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            S3_Path  Sample_ID\n",
       "BF-1402_SI  s3://dp-lab-data/collaborators/arude...       3555\n",
       "BF-1472_LI  s3://dp-lab-data/collaborators/arude...       3571\n",
       "BD-1495_1   s3://dp-lab-data/collaborators/arude...       3557"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read barcodes from file\n",
    "# Note: Must be subset to HTO or CITE barcodes before next step!\n",
    "barcodes = get_bcs_manual(path_to_excel)\n",
    "# barcodes = barcodes[\n",
    "#     barcodes[\"Description\"].str.contains(\"SS1\") |\n",
    "#     barcodes[\"Description\"].str.contains(\"SS2\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barcode</th>\n",
       "      <th>DNA_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>BP Shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTCTTTGTCAGTGCA</td>\n",
       "      <td>A0006</td>\n",
       "      <td>anti-human CD86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTTGTCCGACAATAC</td>\n",
       "      <td>A0007</td>\n",
       "      <td>anti-human CD274 (B7-H1, PD-L1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGATAGAAACAGACC</td>\n",
       "      <td>A0020</td>\n",
       "      <td>anti-human CD270 (HVEM, TR2)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATCACATCGTTGCCA</td>\n",
       "      <td>A0023</td>\n",
       "      <td>anti-human CD155 (PVR)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACCTTCCGTCTAAG</td>\n",
       "      <td>A0024</td>\n",
       "      <td>anti-human CD112 (Nectin-2)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>AACTTCTGTGGTAGC</td>\n",
       "      <td>A0584</td>\n",
       "      <td>anti-human TCR V{LATIN CAPITAL LIGAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>CTTCCGATTCATTCA</td>\n",
       "      <td>A0139</td>\n",
       "      <td>anti-human TCR {LATIN CAPITAL LIGATU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>AGCTGTAAGTTTCGG</td>\n",
       "      <td>A0166</td>\n",
       "      <td>anti-human CD66b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>AAGTGATGGTATCTG</td>\n",
       "      <td>A0583</td>\n",
       "      <td>anti-human TCR V{LATIN CAPITAL LIGAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>TCACCAGTACCTAGT</td>\n",
       "      <td>A0392</td>\n",
       "      <td>anti-human CD15 (SSEA-1)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Barcode DNA_ID                              Description  BP Shift\n",
       "0    GTCTTTGTCAGTGCA  A0006                          anti-human CD86         0\n",
       "1    GTTGTCCGACAATAC  A0007          anti-human CD274 (B7-H1, PD-L1)         0\n",
       "2    TGATAGAAACAGACC  A0020             anti-human CD270 (HVEM, TR2)         0\n",
       "3    ATCACATCGTTGCCA  A0023                   anti-human CD155 (PVR)         0\n",
       "4    AACCTTCCGTCTAAG  A0024              anti-human CD112 (Nectin-2)         0\n",
       "..               ...    ...                                      ...       ...\n",
       "165  AACTTCTGTGGTAGC  A0584  anti-human TCR V{LATIN CAPITAL LIGAT...         0\n",
       "166  CTTCCGATTCATTCA  A0139  anti-human TCR {LATIN CAPITAL LIGATU...         0\n",
       "167  AGCTGTAAGTTTCGG  A0166                         anti-human CD66b         0\n",
       "168  AAGTGATGGTATCTG  A0583  anti-human TCR V{LATIN CAPITAL LIGAT...         0\n",
       "169  TCACCAGTACCTAGT  A0392                 anti-human CD15 (SSEA-1)         0\n",
       "\n",
       "[170 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd85b56be9894e31b2f4214b4f9058b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload barcodes for all samples\n",
    "# Note: Uploads same barcodes to s3 for all samples\n",
    "path_to_csv = path_to_excel.replace(\".xlsx\", \".csv\")\n",
    "barcodes.to_csv(path_to_csv, header=False, index=False)\n",
    "for s3_path in tqdm(samples[\"S3_Path\"]):\n",
    "    cmd = f\"aws s3 cp {path_to_csv} {s3_path}/{output_dirname}/tag-list.csv\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Assumes GEX data is recorded in database\n",
    "samples[\"Whitelist_Params\"] = samples[\"Sample_ID\"].apply(\n",
    "    lambda x: get_wl_params(x, creds)\n",
    ")\n",
    "assert ~samples[\"Whitelist_Params\"].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Adds same barcode parameters for all samples\n",
    "samples[\"BC_Params\"] = samples[\"Sample_ID\"].apply(\n",
    "    lambda x: get_bc_params_manual(barcodes, prefix, platform, creds)\n",
    ")\n",
    "assert ~samples[\"BC_Params\"].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FASTQ paths from S3\n",
    "# Note: Uses same FASTQ file ids for all samples\n",
    "fastq_file_ids = fastq_map[prefix]\n",
    "samples[\"FASTQs\"] = samples[\"S3_Path\"].apply(lambda x: get_fastqs(x, fastq_file_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum inputs and labels fields from templates\n",
    "conjugation = samples[\"BC_Params\"].apply(lambda x: x[\"conjugation\"]).values[0] # conjugation must be same for all samples\n",
    "template_prefix = get_template(prefix, conjugation)\n",
    "with open(f\"{config_dir}/{template_prefix}.inputs.json\") as f:\n",
    "    std_inputs_fields = list(json.load(f).keys())\n",
    "    \n",
    "with open(f\"{config_dir}/{template_prefix}.labels.json\") as f:\n",
    "    std_labels_fields = list(json.load(f).keys())\n",
    "    \n",
    "# Annotate all samples with workflow inputs and labels\n",
    "inputs = pd.DataFrame(index=samples.index, columns=std_inputs_fields,)\n",
    "labels = pd.DataFrame(index=samples.index, columns=std_labels_fields,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate inputs\n",
    "inputs[f\"{prefix}.sampleName\"] = inputs.index\n",
    "inputs[f\"{prefix}.scRnaSeqPlatform\"] = platform # may need to change\n",
    "inputs[f\"{prefix}.lengthR1\"] = samples[\"BC_Params\"].apply(lambda x: x[\"umi\"])\n",
    "inputs[f\"{prefix}.lengthR2\"] = samples[\"BC_Params\"].apply(lambda x: x[\"seq_length\"])\n",
    "inputs[f\"{prefix}.cellBarcodeWhitelistUri\"] = samples[\"Whitelist_Params\"].apply(lambda x: x[\"uri\"])\n",
    "inputs[f\"{prefix}.cellBarcodeWhiteListMethod\"] = samples[\"Whitelist_Params\"].apply(lambda x: x[\"method\"])\n",
    "inputs[f\"{prefix}.{'tagList' if (prefix=='CiteSeq') else 'hashTagList'}\"] = \\\n",
    "    samples[\"S3_Path\"] + f\"/{output_dirname}/tag-list.csv\" #TODO: Ask about changing all to 'tagList'\n",
    "inputs[f\"{prefix}.cbStartPos\"] = 1\n",
    "inputs[f\"{prefix}.cbEndPos\"] = samples[\"BC_Params\"].apply(lambda x: x[\"cb\"])\n",
    "inputs[f\"{prefix}.umiStartPos\"] = inputs[f\"{prefix}.cbEndPos\"]+1\n",
    "inputs[f\"{prefix}.umiEndPos\"] = samples[\"BC_Params\"].apply(lambda x: x[\"umi\"])\n",
    "inputs[f\"{prefix}.trimPos\"] = samples[\"BC_Params\"].apply(lambda x: x[\"bp_shift\"])\n",
    "inputs[f\"{prefix}.translate10XBarcodes\"] = \\\n",
    "    (inputs[f\"{prefix}.scRnaSeqPlatform\"] == \"10x_v3\") & \\\n",
    "    (samples[\"BC_Params\"].apply(lambda x: x[\"conjugation\"] == \"B\"))\n",
    "inputs[f\"{prefix}.dockerRegistry\"] = common_docker_registry\n",
    "for file_id in fastq_file_ids: # Set FASTQs\n",
    "    inputs[f\"{prefix}.uriFastq{file_id}\"] = samples[\"FASTQs\"].apply(lambda x: x[file_id])\n",
    "\n",
    "# ********************\n",
    "# Defaults\n",
    "# Note: These may need to be changed on a per-sample or per-execution basis\n",
    "\n",
    "inputs[f\"{prefix}.slidingWindowSearch\"] = False\n",
    "inputs[f\"{prefix}.cbCollapsingDistance\"] = 1\n",
    "inputs[f\"{prefix}.umiCollapsingDistance\"] = 1\n",
    "inputs[f\"{prefix}.numExpectedCells\"] = 0\n",
    "# Need trick to set dictionary for each row\n",
    "common_resource_spec = {\n",
    "    \"cpu\": 32,\n",
    "    \"memory\": -1,\n",
    "}\n",
    "inputs[f\"{prefix}.resourceSpec\"] = inputs.iloc[:, 0].apply(lambda x: common_resource_spec)\n",
    "if prefix == \"Hashtag\":\n",
    "    inputs[f\"{prefix}.minCount\"] = 10\n",
    "\n",
    "# ********************\n",
    "\n",
    "# Annotate labels\n",
    "labels[\"pipelineType\"] = pipeline_type\n",
    "labels[\"project\"] = samples[\"Sample_ID\"].apply(lambda x: get_project_id(x, creds[\"user\"], creds[\"password\"]))\n",
    "labels[\"sample\"] = labels.index\n",
    "labels[\"owner\"] = creds[\"user\"]\n",
    "labels[\"destination\"] = samples['S3_Path'] + \"/\" + output_dirname\n",
    "labels[\"transfer\"] = \"-\"\n",
    "labels[\"comment\"] = creds[\"user\"]\n",
    "\n",
    "assert (std_inputs_fields == list(inputs.columns)) & (inputs.notna().values.all())\n",
    "assert (std_labels_fields == list(labels.columns)) & (labels.notna().values.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CiteSeq.uriFastqR1</th>\n",
       "      <th>CiteSeq.uriFastqR2</th>\n",
       "      <th>CiteSeq.sampleName</th>\n",
       "      <th>CiteSeq.scRnaSeqPlatform</th>\n",
       "      <th>CiteSeq.lengthR1</th>\n",
       "      <th>CiteSeq.lengthR2</th>\n",
       "      <th>CiteSeq.cellBarcodeWhitelistUri</th>\n",
       "      <th>CiteSeq.cellBarcodeWhiteListMethod</th>\n",
       "      <th>CiteSeq.tagList</th>\n",
       "      <th>CiteSeq.cbStartPos</th>\n",
       "      <th>...</th>\n",
       "      <th>CiteSeq.umiStartPos</th>\n",
       "      <th>CiteSeq.umiEndPos</th>\n",
       "      <th>CiteSeq.trimPos</th>\n",
       "      <th>CiteSeq.slidingWindowSearch</th>\n",
       "      <th>CiteSeq.translate10XBarcodes</th>\n",
       "      <th>CiteSeq.cbCollapsingDistance</th>\n",
       "      <th>CiteSeq.umiCollapsingDistance</th>\n",
       "      <th>CiteSeq.numExpectedCells</th>\n",
       "      <th>CiteSeq.resourceSpec</th>\n",
       "      <th>CiteSeq.dockerRegistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IM-1356_Ru553B_1</th>\n",
       "      <td>[s3://dp-lab-data/SCRI_Projects/HTAN...</td>\n",
       "      <td>[s3://dp-lab-data/SCRI_Projects/HTAN...</td>\n",
       "      <td>IM-1356_Ru553B_1</td>\n",
       "      <td>10x_v3</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>s3://dp-lab-data/SCRI_Projects/HTAN_...</td>\n",
       "      <td>SeqcDenseCountsMatrixCsv</td>\n",
       "      <td>s3://dp-lab-data/SCRI_Projects/HTAN_...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'cpu': 32, 'memory': -1}</td>\n",
       "      <td>quay.io/hisplan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       CiteSeq.uriFastqR1  \\\n",
       "IM-1356_Ru553B_1  [s3://dp-lab-data/SCRI_Projects/HTAN...   \n",
       "\n",
       "                                       CiteSeq.uriFastqR2 CiteSeq.sampleName  \\\n",
       "IM-1356_Ru553B_1  [s3://dp-lab-data/SCRI_Projects/HTAN...   IM-1356_Ru553B_1   \n",
       "\n",
       "                 CiteSeq.scRnaSeqPlatform  CiteSeq.lengthR1  CiteSeq.lengthR2  \\\n",
       "IM-1356_Ru553B_1                   10x_v3                28                15   \n",
       "\n",
       "                          CiteSeq.cellBarcodeWhitelistUri  \\\n",
       "IM-1356_Ru553B_1  s3://dp-lab-data/SCRI_Projects/HTAN_...   \n",
       "\n",
       "                 CiteSeq.cellBarcodeWhiteListMethod  \\\n",
       "IM-1356_Ru553B_1           SeqcDenseCountsMatrixCsv   \n",
       "\n",
       "                                          CiteSeq.tagList  CiteSeq.cbStartPos  \\\n",
       "IM-1356_Ru553B_1  s3://dp-lab-data/SCRI_Projects/HTAN_...                   1   \n",
       "\n",
       "                  ...  CiteSeq.umiStartPos  CiteSeq.umiEndPos  \\\n",
       "IM-1356_Ru553B_1  ...                   17                 28   \n",
       "\n",
       "                  CiteSeq.trimPos  CiteSeq.slidingWindowSearch  \\\n",
       "IM-1356_Ru553B_1                0                        False   \n",
       "\n",
       "                  CiteSeq.translate10XBarcodes  CiteSeq.cbCollapsingDistance  \\\n",
       "IM-1356_Ru553B_1                         False                             1   \n",
       "\n",
       "                  CiteSeq.umiCollapsingDistance  CiteSeq.numExpectedCells  \\\n",
       "IM-1356_Ru553B_1                              1                         0   \n",
       "\n",
       "                       CiteSeq.resourceSpec CiteSeq.dockerRegistry  \n",
       "IM-1356_Ru553B_1  {'cpu': 32, 'memory': -1}        quay.io/hisplan  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>project</th>\n",
       "      <th>sample</th>\n",
       "      <th>owner</th>\n",
       "      <th>destination</th>\n",
       "      <th>transfer</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IM-1356_Ru553B_1</th>\n",
       "      <td>CITE-seq</td>\n",
       "      <td>HTAN_CITEseq</td>\n",
       "      <td>IM-1356_Ru553B_1</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/SCRI_Projects/HTAN_...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pipelineType       project            sample     owner  \\\n",
       "IM-1356_Ru553B_1     CITE-seq  HTAN_CITEseq  IM-1356_Ru553B_1  moormana   \n",
       "\n",
       "                                              destination transfer   comment  \n",
       "IM-1356_Ru553B_1  s3://dp-lab-data/SCRI_Projects/HTAN_...        -  moormana  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecadb35db68428887f127dc03248d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdouts = [] # to store all outputs\n",
    "process = True\n",
    "\n",
    "with tqdm(samples.index) as t:\n",
    "\n",
    "    for sample_name in t:\n",
    "\n",
    "        # Write inputs and labels to file\n",
    "        path_to_inputs = f\"{config_dir}/{sample_name}_{prefix}.inputs.json\"\n",
    "        with open(path_to_inputs, \"w\") as f_inputs:\n",
    "            json.dump(inputs.loc[sample_name].to_dict(), f_inputs, indent=4, cls=NpEncoder)\n",
    "\n",
    "        path_to_labels = f\"{config_dir}/{sample_name}_{prefix}.labels.json\"\n",
    "        with open(path_to_labels, \"w\") as f_labels:\n",
    "            json.dump(labels.loc[sample_name].to_dict(), f_labels, indent=4, cls=NpEncoder)\n",
    "\n",
    "        if process:\n",
    "            stdouts.append(run(\n",
    "                workflow_path = workflow_dir,\n",
    "                execp = path_to_exec,\n",
    "                secrets = path_to_cromwell_secrets,\n",
    "                inputs = path_to_inputs,\n",
    "                labels = path_to_labels,\n",
    "                options = path_to_options,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': ['/Users/moormana/scing/bin/sharp-0.0.13/submit-citeseq.sh',\n",
       "   '-k',\n",
       "   '/Users/moormana/.cromwell/cromwell-secrets.json',\n",
       "   '-i',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/IM-1356_Ru553B_1_CiteSeq.inputs.json',\n",
       "   '-l',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/configs/IM-1356_Ru553B_1_CiteSeq.labels.json',\n",
       "   '-o',\n",
       "   '/Users/moormana/scing/bin/sharp-0.0.13/Sharp.options.aws.json'],\n",
       "  'returncode': 0,\n",
       "  'stdout': '{\"id\":\"36e1b236-1170-4cdc-85ba-27b7c62082e9\",\"status\":\"Submitted\"}\\n',\n",
       "  'stderr': ''}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
