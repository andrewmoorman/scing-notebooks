{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, subprocess, boto3, json, shlex, mysql, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from s3path import S3Path\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from packaging import version\n",
    "pd.set_option(\"display.max_colwidth\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy encoder for JSON from pandas series\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from SCRIdb\n",
    "def get_s3_objects(bucket, key, pattern, full_uri=False):\n",
    "    \n",
    "    s3r = boto3.resource(\"s3\")\n",
    "    bucket_s3 = s3r.Bucket(bucket)\n",
    "    objects = []\n",
    "    for obj in bucket_s3.objects.filter(Prefix=key):\n",
    "        hit = pattern.search(obj.key)\n",
    "        if hit:\n",
    "            objects.append(obj.key)\n",
    "    if full_uri:\n",
    "        objects = [f\"s3://{bucket}/{o}\" for o in objects]\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query, user, password):\n",
    "    with connect(\n",
    "        host=\"peer-lab-db.cggxmlwgzzpw.us-east-1.rds.amazonaws.com\",\n",
    "        database=\"peer_lab_db\",\n",
    "        user=user,\n",
    "        password=password,\n",
    "    ) as connection:\n",
    "        with connection.cursor(buffered=True) as cursor:\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_species(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_species = \"peer_lab_db.species\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_species}.Species\n",
    "        FROM {table_species}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_species}.id = {table_genome_idx}.species_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sc_tech(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sc_tech}.sc_Tech\n",
    "        FROM {table_sc_tech}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_sc_tech}.id = {table_genome_idx}.scTech_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sample_id(sample_name, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sample_data}.id\n",
    "        FROM {table_sample_data}\n",
    "        WHERE {table_sample_data}.Sample=\"{sample_name}\"\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_project_id(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_project_data = \"peer_lab_db.project_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_project_data}.projectName\n",
    "        FROM {table_project_data}\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_project_data}.id = {table_sample_data}.projectData_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SEQC_version(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 cp {loc}/seqc-results/seqc_log.txt -\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        version = re.match(r\".*SEQC=v(\\d+\\.\\d+\\.\\d+).*\", out)[1]\n",
    "        return version\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_prefix(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 ls {loc}/seqc-results/\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        \n",
    "        # Note: I'm expecting the aligned bam file to be in loc\n",
    "        bam_pattern = re.compile(r\"(.*)_Aligned\\.out\\.bam$\")\n",
    "        filename = list(filter(bam_pattern.match, out.split()))[0]\n",
    "        file_prefix = re.match(bam_pattern, filename)[1]\n",
    "        return file_prefix\n",
    "    except:\n",
    "        raise ValueError(f\"BAM file not found in {loc}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference(sample_id):\n",
    "    # Get species from database to decide reference\n",
    "    species = get_species(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"Human\" in species:\n",
    "        return \"s3://seqc-public/genomes/hg38_long_polya/annotations.gtf\"\n",
    "    elif \"Mouse\" in species:\n",
    "        return \"s3://seqc-public/genomes/mm38_long_polya/annotations.gtf\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Species: {species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bc_whitelist(sample_id):\n",
    "    # Get version from database to decide whitelist\n",
    "    sc_tech = get_sc_tech(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"V3\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v3/flat/3M-february-2018.txt\"\n",
    "    elif \"V2\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v2/flat/737K-august-2016.txt\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Technology: {sc_tech}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(\n",
    "    workflow_path: str,\n",
    "    execp: str,\n",
    "    secrets: str,\n",
    "    inputs: str,\n",
    "    labels: str,\n",
    "    options: str,\n",
    "):\n",
    "    # change working directory to the pipeline package\n",
    "    oldwd = os.getcwd()\n",
    "    os.chdir(workflow_path)\n",
    "    \n",
    "    # execute the pipeline command\n",
    "    cmd = f\"{workflow_path}/{execp} -k {secrets} -i {inputs} -l {labels} -o {options}\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)\n",
    "    out = var.__dict__\n",
    "    \n",
    "    # change working directory back\n",
    "    os.chdir(oldwd)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of docker files\n",
    "common_docker_registry = \"quay.io/hisplan\"\n",
    "\n",
    "prefix = \"Velopipe2\" # Workflow to run; also .wdl filename prefix\n",
    "pipeline_type = prefix # field in *.labels.json\n",
    "output_dirname = \"velopipe\"\n",
    "\n",
    "# If need to add comment, put here\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velopipe-specific parameters\n",
    "min_SEQC_version = \"0.2.9\"\n",
    "options_prefix=\"Velopipe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of workflow-related directories and files\n",
    "path_to_cromwell_secrets = f\"{Path.home()}/.cromwell/cromwell-secrets.json\" # CHANGE THIS\n",
    "workflow_dir = f\"{Path.home()}/scing/bin/velopipe-0.0.9\" # CHANGE THIS\n",
    "path_to_exec = f\"{workflow_dir}/submit.sh\" # CHANGE THIS FOR SHARP\n",
    "config_dir = f\"{workflow_dir}/config\"\n",
    "path_to_options = f\"{workflow_dir}/{options_prefix}.options.aws.json\"\n",
    "\n",
    "# Other file locations\n",
    "db_credentials_path = f\"{Path.home()}/.config.json\" # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials based on SCRIdb CLI config file\n",
    "with open(db_credentials_path) as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Samples on which to run Velopipe\n",
    "# Note: Assumes data is transferred to AWS S3 (this should be an s3 location)\n",
    "sample_paths = [\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG146Li/\",\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG146P/\",\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG146N/\",\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG150Li/\",\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG150P/\",\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG150N/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples on which to run Velopipe\n",
    "# Note: Assumes data is transferred to AWS S3 (this should be an s3 location)\n",
    "# Note: Assumes directory name is name of sample\n",
    "sample_paths = [\n",
    "    \"s3://dp-lab-data/moormana/CRC_Triplets/KG146Li/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples must be re-run with SEQC >= v0.2.9: \n"
     ]
    }
   ],
   "source": [
    "# Get information for all samples\n",
    "sample_paths = [s.strip('/') for s in sample_paths] # remove trailing slash if exists\n",
    "sample_names = [os.path.basename(s) for s in sample_paths]\n",
    "samples = pd.DataFrame(\n",
    "    sample_paths,\n",
    "    index=sample_names,\n",
    "    columns=[\"S3_Path\"],\n",
    "    dtype=str,\n",
    ")\n",
    "samples[\"File_Prefix\"] = samples[\"S3_Path\"].apply(get_file_prefix)\n",
    "samples[\"Sample_ID\"] = pd.Series(samples.index).apply(\n",
    "    lambda x: get_sample_id(x, creds['user'], creds['password'])\n",
    ").values\n",
    "samples[\"File_Prefix\"] = samples[\"S3_Path\"].apply(get_file_prefix)\n",
    "\n",
    "# Determine whether samples must be re-run with updated version of SEQC\n",
    "samples[\"SEQC_Version\"] = samples[\"S3_Path\"].apply(get_SEQC_version)\n",
    "is_outdated = samples[\"SEQC_Version\"].apply(lambda x: False if (x=='N/A') else (version.parse(x) < version.parse(min_SEQC_version)))\n",
    "outdated = samples[is_outdated]\n",
    "print(f\"{len(outdated)} samples must be re-run with SEQC >= v{min_SEQC_version}: {', '.join(outdated.index.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum inputs and labels fields from templates\n",
    "with open(f\"{workflow_dir}/config/template.inputs.json\") as f:\n",
    "    std_inputs_fields = list(json.load(f).keys())\n",
    "    \n",
    "with open(f\"{workflow_dir}/config/template.labels.json\") as f:\n",
    "    std_labels_fields = list(json.load(f).keys())\n",
    "    \n",
    "# Annotate all samples with workflow inputs and labels\n",
    "inputs = pd.DataFrame(index=samples.index, columns=std_inputs_fields,)\n",
    "labels = pd.DataFrame(index=samples.index, columns=std_labels_fields,)\n",
    "\n",
    "# Annotate inputs\n",
    "inputs[f\"{prefix}.sampleName\"] = inputs.index # may need to change\n",
    "inputs[f\"{prefix}.numOfChunks\"] = int(20) # may need to change\n",
    "inputs[f\"{prefix}.gtf\"] = samples[\"Sample_ID\"].apply(get_reference)\n",
    "inputs[f\"{prefix}.fullBarcodeWhitelist\"] = samples[\"Sample_ID\"].apply(get_bc_whitelist)\n",
    "inputs[f\"{prefix}.dockerRegistry\"] = common_docker_registry\n",
    "samples[\"Full_S3_Path\"] = samples[\"S3_Path\"] + \"/seqc-results/\" +  samples[\"File_Prefix\"]\n",
    "inputs[f\"{prefix}.bam\"] = samples[\"Full_S3_Path\"] + \"_Aligned.out.bam\"\n",
    "inputs[f\"{prefix}.cbCorrection\"] = samples[\"Full_S3_Path\"] + \"_cb-correction.csv.gz\"\n",
    "inputs[f\"{prefix}.umiCorrection\"] = samples[\"Full_S3_Path\"] + \"_umi-correction.csv.gz\"\n",
    "\n",
    "# ********************\n",
    "# Note: Whitelist may need to be changed on a per-sample basis\n",
    "\n",
    "inputs[f\"{prefix}.filteredBarcodes\"] = \"s3://dp-lab-data/moormana/CRC_Triplets/KG146Li/seqc-results/KG146Li_Epi_dense.csv\"\n",
    "\n",
    "# ********************\n",
    "\n",
    "# Annotate labels\n",
    "labels[\"pipelineType\"] = pipeline_type\n",
    "labels[\"project\"] = samples[\"Sample_ID\"].apply(lambda x: get_project_id(x, creds[\"user\"], creds[\"password\"]))\n",
    "labels[\"sample\"] = labels.index\n",
    "labels[\"owner\"] = creds[\"user\"]\n",
    "labels[\"destination\"] = samples['S3_Path'] + \"/\" + output_dirname\n",
    "labels[\"transfer\"] = \"-\"\n",
    "labels[\"comment\"] = creds[\"user\"]\n",
    "\n",
    "assert (std_inputs_fields == list(inputs.columns)) & (inputs.notna().values.all())\n",
    "assert (std_labels_fields == list(labels.columns)) & (labels.notna().values.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Velopipe2.sampleName</th>\n",
       "      <th>Velopipe2.filteredBarcodes</th>\n",
       "      <th>Velopipe2.bam</th>\n",
       "      <th>Velopipe2.numOfChunks</th>\n",
       "      <th>Velopipe2.gtf</th>\n",
       "      <th>Velopipe2.fullBarcodeWhitelist</th>\n",
       "      <th>Velopipe2.cbCorrection</th>\n",
       "      <th>Velopipe2.umiCorrection</th>\n",
       "      <th>Velopipe2.dockerRegistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KG146Li</th>\n",
       "      <td>KG146Li</td>\n",
       "      <td>s3://dp-lab-data/moormana/CRC_Triple...</td>\n",
       "      <td>s3://dp-lab-data/moormana/CRC_Triple...</td>\n",
       "      <td>20</td>\n",
       "      <td>s3://seqc-public/genomes/hg38_long_p...</td>\n",
       "      <td>s3://seqc-public/barcodes/ten_x_v3/f...</td>\n",
       "      <td>s3://dp-lab-data/moormana/CRC_Triple...</td>\n",
       "      <td>s3://dp-lab-data/moormana/CRC_Triple...</td>\n",
       "      <td>quay.io/hisplan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Velopipe2.sampleName               Velopipe2.filteredBarcodes  \\\n",
       "KG146Li              KG146Li  s3://dp-lab-data/moormana/CRC_Triple...   \n",
       "\n",
       "                                   Velopipe2.bam  Velopipe2.numOfChunks  \\\n",
       "KG146Li  s3://dp-lab-data/moormana/CRC_Triple...                     20   \n",
       "\n",
       "                                   Velopipe2.gtf  \\\n",
       "KG146Li  s3://seqc-public/genomes/hg38_long_p...   \n",
       "\n",
       "                  Velopipe2.fullBarcodeWhitelist  \\\n",
       "KG146Li  s3://seqc-public/barcodes/ten_x_v3/f...   \n",
       "\n",
       "                          Velopipe2.cbCorrection  \\\n",
       "KG146Li  s3://dp-lab-data/moormana/CRC_Triple...   \n",
       "\n",
       "                         Velopipe2.umiCorrection Velopipe2.dockerRegistry  \n",
       "KG146Li  s3://dp-lab-data/moormana/CRC_Triple...          quay.io/hisplan  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>project</th>\n",
       "      <th>sample</th>\n",
       "      <th>owner</th>\n",
       "      <th>destination</th>\n",
       "      <th>transfer</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KG146Li</th>\n",
       "      <td>Velopipe2</td>\n",
       "      <td>CRC Primary Met Organoid</td>\n",
       "      <td>KG146Li</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/moormana/CRC_Triple...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pipelineType                   project   sample     owner  \\\n",
       "KG146Li    Velopipe2  CRC Primary Met Organoid  KG146Li  moormana   \n",
       "\n",
       "                                     destination transfer   comment  \n",
       "KG146Li  s3://dp-lab-data/moormana/CRC_Triple...        -  moormana  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e07ef643f26402fac5ce4c1c07e2229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdouts = [] # to store all outputs\n",
    "process = True\n",
    "\n",
    "with tqdm(samples.index) as t:\n",
    "\n",
    "    for sample_name in t:\n",
    "\n",
    "        # Write inputs and labels to file\n",
    "        path_to_inputs = f\"{config_dir}/{sample_name}.inputs.json\"\n",
    "        with open(path_to_inputs, \"w\") as f_inputs:\n",
    "            json.dump(inputs.loc[sample_name].to_dict(), f_inputs, indent=4, cls=NpEncoder)\n",
    "\n",
    "        path_to_labels = f\"{config_dir}/{sample_name}.labels.json\"\n",
    "        with open(path_to_labels, \"w\") as f_labels:\n",
    "            json.dump(labels.loc[sample_name].to_dict(), f_labels, indent=4, cls=NpEncoder)\n",
    "\n",
    "        if process:\n",
    "            stdouts.append(run(\n",
    "                workflow_path = workflow_dir,\n",
    "                execp = \"submit.sh\",\n",
    "                secrets = path_to_cromwell_secrets,\n",
    "                inputs = path_to_inputs,\n",
    "                labels = path_to_labels,\n",
    "                options = path_to_options,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': ['/Users/moormana/scing/bin/velopipe-0.0.9/submit.sh',\n",
       "   '-k',\n",
       "   '/Users/moormana/.cromwell/cromwell-secrets.json',\n",
       "   '-i',\n",
       "   '/Users/moormana/scing/bin/velopipe-0.0.9/config/KG146Li.inputs.json',\n",
       "   '-l',\n",
       "   '/Users/moormana/scing/bin/velopipe-0.0.9/config/KG146Li.labels.json',\n",
       "   '-o',\n",
       "   '/Users/moormana/scing/bin/velopipe-0.0.9/Velopipe.options.aws.json'],\n",
       "  'returncode': 0,\n",
       "  'stdout': '{\"id\":\"61f746cb-437c-4a88-ab84-2100521ef9e3\",\"status\":\"Submitted\"}\\n',\n",
       "  'stderr': ''}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
