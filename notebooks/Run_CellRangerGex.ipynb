{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, subprocess, boto3, json, shlex, mysql, os, urllib, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from s3path import S3Path\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from packaging import version\n",
    "pd.set_option(\"display.max_colwidth\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTQ reads/indices required for each workflow\n",
    "fastq_map = {\n",
    "    'Hashtag': ['R1','R2'],\n",
    "    'CiteSeq': ['R1','R2'],\n",
    "    'AsapSeq': ['R1','R2','R3'],\n",
    "    'CellRangerATAC': ['I1','R1','R2','R3'],\n",
    "    'CellRangerGex': ['I1','R1','R2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fastq file paths on S3 for each file id\n",
    "# Returns dictionary from id to s3 path\n",
    "# Throws exception if FASTQs don't exist for any id\n",
    "def get_fastqs(\n",
    "    path: str, # path to directory containing FASTQ files\n",
    "    fastq_file_ids: list, # FASTQ file ids needed for this run type (e.g. I1, R1, R2, etc.)\n",
    "    folder: str = \"\",\n",
    "):\n",
    "    fastq_map = dict()\n",
    "    _, bucket, key, _, _ = urllib.parse.urlsplit(f\"{path}/{folder}\")\n",
    "    for fid in fastq_file_ids:\n",
    "        files = get_s3_objects(\n",
    "            bucket, key.lstrip(\"/\"),\n",
    "            re.compile(f\"_{fid}_\\d{{3}}.fastq.gz$\")\n",
    "        )\n",
    "        try:\n",
    "            assert files, f\"AssertionError: Missing `{fid}` archives!\"\n",
    "            fastq_map[fid] = [os.path.join(\"s3://\", bucket, str(f)) for f in files]\n",
    "        except AssertionError as err:\n",
    "            logging.warning(\"%s\\n\\t %s\", err, path)\n",
    "            return\n",
    "    return fastq_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from SCRIdb\n",
    "def get_s3_objects(bucket, key, pattern, full_uri=False):\n",
    "    \n",
    "    s3r = boto3.resource(\"s3\")\n",
    "    bucket_s3 = s3r.Bucket(bucket)\n",
    "    objects = []\n",
    "    for obj in bucket_s3.objects.filter(Prefix=key):\n",
    "        hit = pattern.search(obj.key)\n",
    "        if hit:\n",
    "            objects.append(obj.key)\n",
    "    if full_uri:\n",
    "        objects = [f\"s3://{bucket}/{o}\" for o in objects]\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FASTQ sample name from list of files\n",
    "# Note: FASTQ name is file name up to lane id (e.g. L001, L002, etc.)\n",
    "def get_fastqs_name(fastqs):\n",
    "    fastq_name_re = r\".*/(.*)_S\\d+_L\\d{3}_[A-Za-z]\\d_\\d{3}.fastq.gz$\"\n",
    "    fastq_names = [re.match(fastq_name_re, x)[1] for x in fastqs]\n",
    "    assert len(set(fastq_names)) == 1 # make sure all names are same\n",
    "    return fastq_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy encoder for JSON from pandas series\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query, user, password):\n",
    "    with connect(\n",
    "        host=\"peer-lab-db.cggxmlwgzzpw.us-east-1.rds.amazonaws.com\",\n",
    "        database=\"peer_lab_db\",\n",
    "        user=user,\n",
    "        password=password,\n",
    "    ) as connection:\n",
    "        with connection.cursor(buffered=True) as cursor:\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_species(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_species = \"peer_lab_db.species\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_species}.Species\n",
    "        FROM {table_species}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_species}.id = {table_genome_idx}.species_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sc_tech(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sc_tech}.sc_Tech\n",
    "        FROM {table_sc_tech}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_sc_tech}.id = {table_genome_idx}.scTech_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sample_id(sample_name, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sample_data}.id\n",
    "        FROM {table_sample_data}\n",
    "        WHERE {table_sample_data}.Sample=\"{sample_name}\"\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_project_id(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_project_data = \"peer_lab_db.project_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_project_data}.projectName\n",
    "        FROM {table_project_data}\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_project_data}.id = {table_sample_data}.projectData_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SEQC_version(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 cp {loc}/seqc-results/seqc_log.txt -\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        version = re.match(r\".*SEQC=v(\\d+\\.\\d+\\.\\d+).*\", out)[1]\n",
    "        return version\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_prefix(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 ls {loc}/seqc-results/\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        \n",
    "        # Note: I'm expecting the aligned bam file to be in loc\n",
    "        bam_pattern = re.compile(r\"(.*)_Aligned\\.out\\.bam$\")\n",
    "        filename = list(filter(bam_pattern.match, out.split()))[0]\n",
    "        file_prefix = re.match(bam_pattern, filename)[1]\n",
    "        return file_prefix\n",
    "    except:\n",
    "        raise ValueError(f\"BAM file not found in {loc}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTQ reads/indices required for each workflow\n",
    "# Shoudl replace with JSON file\n",
    "cr_reference_map = {\n",
    "    'CellRangerArc':\n",
    "    {\n",
    "        'Human': \"https://cf.10xgenomics.com/supp/cell-arc/refdata-cellranger-arc-GRCh38-2020-A.tar.gz\",\n",
    "        'Mouse': \"https://cf.10xgenomics.com/supp/cell-arc/refdata-cellranger-arc-mm10-2020-A-2.0.0.tar.gz\",\n",
    "    },\n",
    "    'CellRangerATAC':\n",
    "    {\n",
    "        'Human': \"https://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-arc-GRCh38-2020-A-2.0.0.tar.gz\",\n",
    "        'Mouse': \"https://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-arc-mm10-2020-A-2.0.0.tar.gz\",\n",
    "    },\n",
    "    'CellRangerGex':\n",
    "    {\n",
    "        'Human': \"https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz\",\n",
    "        'Mouse': \"https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_cr_reference(sample_id, prefix, user, password):\n",
    "    # Get species from database to decide reference\n",
    "    species = get_species(sample_id, user, password)\n",
    "    \n",
    "    # Map to reference locations\n",
    "    try:\n",
    "        return cr_reference_map[prefix][species]\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown Species: {species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bc_whitelist(sample_id):\n",
    "    # Get version from database to decide whitelist\n",
    "    sc_tech = get_sc_tech(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"V3\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v3/flat/3M-february-2018.txt\"\n",
    "    elif \"V2\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v2/flat/737K-august-2016.txt\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Technology: {sc_tech}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(\n",
    "    workflow_path: str,\n",
    "    execp: str,\n",
    "    secrets: str,\n",
    "    inputs: str,\n",
    "    labels: str,\n",
    "    options: str,\n",
    "):\n",
    "    # change working directory to the pipeline package\n",
    "    oldwd = os.getcwd()\n",
    "    os.chdir(workflow_path)\n",
    "    \n",
    "    # execute the pipeline command\n",
    "    cmd = f\"{workflow_path}/{execp} -k {secrets} -i {inputs} -l {labels} -o {options}\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)\n",
    "    out = var.__dict__\n",
    "    \n",
    "    # change working directory back\n",
    "    os.chdir(oldwd)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of docker files\n",
    "common_docker_registry = \"quay.io/hisplan\"\n",
    "\n",
    "prefix = \"CellRangerGex\" # Workflow to run; also .wdl filename prefix\n",
    "pipeline_type = prefix # field in *.labels.json\n",
    "output_dirname = \"cr-gex-results\"\n",
    "\n",
    "# If need to add comment, put here\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of workflow-related directories and files\n",
    "path_to_cromwell_secrets = f\"{Path.home()}/.cromwell/cromwell-secrets.json\" # CHANGE THIS\n",
    "workflow_dir = f\"{Path.home()}/scing/bin/cellranger-gex-6.1.2\" # CHANGE THIS\n",
    "path_to_exec = f\"{workflow_dir}/submit.sh\" # CHANGE THIS FOR SHARP\n",
    "config_dir = f\"{workflow_dir}/configs\"\n",
    "path_to_options = f\"{workflow_dir}/{prefix}.options.aws.json\"\n",
    "\n",
    "# Other file locations\n",
    "db_credentials_path = f\"{Path.home()}/.config.json\" # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials based on SCRIdb CLI config file\n",
    "with open(db_credentials_path) as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SU-1358_C10_T2_on_treatment',\n",
       " 'SU-1377_C11_screening_pancreas',\n",
       " 'SU-1400_B06_screening_pancreas',\n",
       " 'SU-1410_B07_liver_screening',\n",
       " 'SU-1419_C12_liver_screening']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = !aws s3 ls $common_dir/\n",
    "[s.strip()[4:-1] for s in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples on which to run CellRangerATAC\n",
    "# Note: Assumes data is transferred to AWS S3 (this should be an s3 location)\n",
    "# Note: Assumes directory name is name of sample\n",
    "common_dir = \"s3://dp-lab-data/sc-seq/Project_12437_S\"\n",
    "samples = [\n",
    "    'SU-1358_C10_T2_on_treatment',\n",
    "    #'SU-1377_C11_screening_pancreas',\n",
    "    #'SU-1400_B06_screening_pancreas',\n",
    "    #'SU-1410_B07_liver_screening',\n",
    "    #'SU-1419_C12_liver_screening'\n",
    "]\n",
    "sample_paths = [\n",
    "    f\"{common_dir}/{sample}\" for sample in samples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to transgene reference S3\n",
    "# Note: This is an exceptional case\n",
    "# path_to_reference = f\"{common_dir}/transgene_reference/refdata-cellranger/3PS19_SNSEQ-GRCm38-Ensembl-87-transgenes.tar.gz\"\n",
    "path_to_reference = \"https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-mm10-2020-A.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SU-1358_C10_T2_on_treatment']\n"
     ]
    }
   ],
   "source": [
    "# Get information for all samples\n",
    "sample_paths = [s.strip('/') for s in sample_paths] # remove trailing slash if exists\n",
    "sample_names = [os.path.basename(s) for s in sample_paths]\n",
    "\n",
    "print(sample_names)\n",
    "samples = pd.DataFrame(\n",
    "    sample_paths,\n",
    "    index=sample_names,\n",
    "    columns=[\"S3_Path\"],\n",
    "    dtype=str,\n",
    ")\n",
    "samples[\"Sample_ID\"] = pd.Series(samples.index).apply(\n",
    "    lambda x: get_sample_id(x, creds['user'], creds['password'])\n",
    ").values\n",
    "\n",
    "# Get FASTQ paths from S3\n",
    "# Note: Uses same FASTQ file ids for all samples\n",
    "fastq_file_ids = fastq_map[prefix]\n",
    "samples[\"FASTQs\"] = samples[\"S3_Path\"].apply(lambda x: get_fastqs(x, fastq_file_ids, \"FASTQ\"))\n",
    "\n",
    "# Get reference genome location\n",
    "samples[\"Reference\"] = samples[\"Sample_ID\"].apply(lambda x: get_cr_reference(x, prefix, creds[\"user\"], creds[\"password\"]))\n",
    "#samples[\"Reference\"] = path_to_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum inputs and labels fields from templates\n",
    "with open(f\"{config_dir}/template.inputs.json\") as f:\n",
    "    std_inputs_fields = list(json.load(f).keys())\n",
    "    \n",
    "with open(f\"{config_dir}/template.labels.json\") as f:\n",
    "    std_labels_fields = list(json.load(f).keys())\n",
    "    \n",
    "# Annotate all samples with workflow inputs and labels\n",
    "inputs = pd.DataFrame(index=samples.index, columns=std_inputs_fields,)\n",
    "labels = pd.DataFrame(index=samples.index, columns=std_labels_fields,)\n",
    "\n",
    "# Annotate inputs\n",
    "inputs[f\"{prefix}.sampleName\"] = inputs.index # may need to change\n",
    "inputs[f\"{prefix}.inputFastq\"] = samples[\"FASTQs\"].apply(lambda x: np.ravel(list(x.values())))\n",
    "inputs[f\"{prefix}.fastqName\"] = inputs[f\"{prefix}.inputFastq\"].apply(lambda x: get_fastqs_name(x))\n",
    "inputs[f\"{prefix}.referenceUrl\"] = samples[\"Reference\"]                        \n",
    "inputs[f\"{prefix}.includeIntrons\"] = False\n",
    "inputs[f\"{prefix}.expectCells\"] = 5000\n",
    "inputs[f\"{prefix}.memory\"] = 256\n",
    "inputs[f\"{prefix}.dockerRegistry\"] = common_docker_registry\n",
    "\n",
    "# Annotate labels\n",
    "labels[\"pipelineType\"] = pipeline_type\n",
    "labels[\"project\"] = samples[\"Sample_ID\"].apply(lambda x: get_project_id(x, creds[\"user\"], creds[\"password\"]))\n",
    "labels[\"sample\"] = labels.index\n",
    "labels[\"owner\"] = creds[\"user\"]\n",
    "labels[\"destination\"] = samples['S3_Path'] + \"/\" + output_dirname\n",
    "labels[\"transfer\"] = \"-\"\n",
    "labels[\"comment\"] = creds[\"user\"]\n",
    "\n",
    "assert (std_inputs_fields == list(inputs.columns)) & (inputs.notna().values.all())\n",
    "assert (std_labels_fields == list(labels.columns)) & (labels.notna().values.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellRangerGex.sampleName</th>\n",
       "      <th>CellRangerGex.fastqName</th>\n",
       "      <th>CellRangerGex.inputFastq</th>\n",
       "      <th>CellRangerGex.referenceUrl</th>\n",
       "      <th>CellRangerGex.includeIntrons</th>\n",
       "      <th>CellRangerGex.expectCells</th>\n",
       "      <th>CellRangerGex.memory</th>\n",
       "      <th>CellRangerGex.dockerRegistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SU-1358_C10_T2_on_treatment</th>\n",
       "      <td>SU-1358_C10_T2_on_treatment</td>\n",
       "      <td>3447_SU-1358_C10_T2_on_treatment_IGO...</td>\n",
       "      <td>[s3://dp-lab-data/sc-seq/Project_124...</td>\n",
       "      <td>https://cf.10xgenomics.com/supp/cell...</td>\n",
       "      <td>False</td>\n",
       "      <td>5000</td>\n",
       "      <td>256</td>\n",
       "      <td>quay.io/hisplan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                CellRangerGex.sampleName  \\\n",
       "SU-1358_C10_T2_on_treatment  SU-1358_C10_T2_on_treatment   \n",
       "\n",
       "                                             CellRangerGex.fastqName  \\\n",
       "SU-1358_C10_T2_on_treatment  3447_SU-1358_C10_T2_on_treatment_IGO...   \n",
       "\n",
       "                                            CellRangerGex.inputFastq  \\\n",
       "SU-1358_C10_T2_on_treatment  [s3://dp-lab-data/sc-seq/Project_124...   \n",
       "\n",
       "                                          CellRangerGex.referenceUrl  \\\n",
       "SU-1358_C10_T2_on_treatment  https://cf.10xgenomics.com/supp/cell...   \n",
       "\n",
       "                             CellRangerGex.includeIntrons  \\\n",
       "SU-1358_C10_T2_on_treatment                         False   \n",
       "\n",
       "                             CellRangerGex.expectCells  CellRangerGex.memory  \\\n",
       "SU-1358_C10_T2_on_treatment                       5000                   256   \n",
       "\n",
       "                            CellRangerGex.dockerRegistry  \n",
       "SU-1358_C10_T2_on_treatment              quay.io/hisplan  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>project</th>\n",
       "      <th>sample</th>\n",
       "      <th>owner</th>\n",
       "      <th>destination</th>\n",
       "      <th>transfer</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SU-1358_C10_T2_on_treatment</th>\n",
       "      <td>CellRangerGex</td>\n",
       "      <td>POLAR</td>\n",
       "      <td>SU-1358_C10_T2_on_treatment</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/sc-seq/Project_1243...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pipelineType project  \\\n",
       "SU-1358_C10_T2_on_treatment  CellRangerGex   POLAR   \n",
       "\n",
       "                                                  sample     owner  \\\n",
       "SU-1358_C10_T2_on_treatment  SU-1358_C10_T2_on_treatment  moormana   \n",
       "\n",
       "                                                         destination transfer  \\\n",
       "SU-1358_C10_T2_on_treatment  s3://dp-lab-data/sc-seq/Project_1243...        -   \n",
       "\n",
       "                              comment  \n",
       "SU-1358_C10_T2_on_treatment  moormana  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c261084afa9f437daabaecb8054fea46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdouts = [] # to store all outputs\n",
    "process = True\n",
    "\n",
    "with tqdm(samples.index) as t:\n",
    "\n",
    "    for sample_name in t:\n",
    "\n",
    "        # Write inputs and labels to file\n",
    "        path_to_inputs = f\"{config_dir}/{sample_name}.inputs.json\"\n",
    "        with open(path_to_inputs, \"w\") as f_inputs:\n",
    "            json.dump(inputs.loc[sample_name].to_dict(), f_inputs, indent=4, cls=NpEncoder)\n",
    "\n",
    "        path_to_labels = f\"{config_dir}/{sample_name}.labels.json\"\n",
    "        with open(path_to_labels, \"w\") as f_labels:\n",
    "            json.dump(labels.loc[sample_name].to_dict(), f_labels, indent=4, cls=NpEncoder)\n",
    "\n",
    "        if process:\n",
    "            stdouts.append(run(\n",
    "                workflow_path = workflow_dir,\n",
    "                execp = \"submit.sh\",\n",
    "                secrets = path_to_cromwell_secrets,\n",
    "                inputs = path_to_inputs,\n",
    "                labels = path_to_labels,\n",
    "                options = path_to_options,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': ['/Users/moormana/scing/bin/cellranger-gex-6.1.2/submit.sh',\n",
       "   '-k',\n",
       "   '/Users/moormana/.cromwell/cromwell-secrets.json',\n",
       "   '-i',\n",
       "   '/Users/moormana/scing/bin/cellranger-gex-6.1.2/configs/SU-1358_C10_T2_on_treatment.inputs.json',\n",
       "   '-l',\n",
       "   '/Users/moormana/scing/bin/cellranger-gex-6.1.2/configs/SU-1358_C10_T2_on_treatment.labels.json',\n",
       "   '-o',\n",
       "   '/Users/moormana/scing/bin/cellranger-gex-6.1.2/CellRangerGex.options.aws.json'],\n",
       "  'returncode': 0,\n",
       "  'stdout': '{\"id\":\"1931681b-646b-4ba9-ac7e-01816b9d30cc\",\"status\":\"Submitted\"}\\n',\n",
       "  'stderr': ''}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
