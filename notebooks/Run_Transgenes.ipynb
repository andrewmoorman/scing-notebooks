{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, subprocess, boto3, json, shlex, mysql, os, urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from s3path import S3Path\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from packaging import version\n",
    "pd.set_option(\"display.max_colwidth\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from species to S3 locations of annotation and fasta files\n",
    "ref_map = {\n",
    "    (\"GRCh38\", 85):\n",
    "    (\n",
    "        \"s3://seqc-public/genomes/hg38_long_poly/annotations.gtf\",\n",
    "        \"s3://seqc-public/genomes/hg38_long_poly/homo_sapiens.fa\",\n",
    "    ),\n",
    "    (\"GRCm38\", 87):\n",
    "    (\n",
    "        \"s3://seqc-public/genomes/mm38_long_polya/annotations.gtf\",\n",
    "        \"s3://seqc-public/genomes/mm38_long_polya/mus_musculus.fa\",\n",
    "    ),\n",
    "    (\"GRCh38\", 100):\n",
    "    (\n",
    "        \"s3://seqc-public/genomes/GRCh38-Ensembl-100/annotations.gtf\",\n",
    "        \"s3://seqc-public/genomes/GRCh38-Ensembl-100/homo_sapiens.fa\",\n",
    "    ),\n",
    "    (\"GRCm38\", 100):\n",
    "    (\n",
    "        \"s3://seqc-public/genomes/GRCm38-Ensembl-100/annotations.gtf\",\n",
    "        \"s3://seqc-public/genomes/GRCm38-Ensembl-100/mus_musculus.fa\",\n",
    "    ),\n",
    "    #(('Human', 'Mouse'), ('GRCh38', 'GRCm38'), 100), : No FASTA as of 2021-01-15\n",
    "}\n",
    "\n",
    "# Map from species column of form to Ensembl prefix\n",
    "ensembl_map = {\n",
    "    \"Human\": \"ENS\",\n",
    "    \"Mouse\": \"ENSMUS\",\n",
    "    ('Human', 'Mouse'): \"ENS\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_species(response):\n",
    "    \n",
    "    species_sub, ensembl_sub = response.split(\"/\")\n",
    "\n",
    "    # Get species and species id\n",
    "    species_pattern = r'([a-zA-Z]*) \\((.*?)\\)'\n",
    "    species_matches = re.findall(species_pattern, species_sub)\n",
    "    if len(species_matches)>1:\n",
    "        names = (match[0] for match in species_matches)\n",
    "        ids = (match[1] for match in species_matches)\n",
    "        species = (names, ids)\n",
    "    else: \n",
    "        species = species_matches[0]\n",
    "\n",
    "    # Get ensembl version\n",
    "    ensembl_pattern = r'Ensembl (\\d*)'\n",
    "    ensembl = re.findall(ensembl_pattern, ensembl_sub)[0]\n",
    "\n",
    "    return species + (int(ensembl),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTQ reads/indices required for each workflow\n",
    "fastq_map = {\n",
    "    'Hashtag': ['R1', 'R2'],\n",
    "    'CiteSeq': ['R1', 'R2'],\n",
    "    'AsapSeq': ['R1', 'R2', 'R3'],\n",
    "    'CellRangerATAC': ['I1', 'R1', 'R2', 'R3'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fastq file paths on S3 for each file id\n",
    "# Returns dictionary from id to s3 path\n",
    "# Throws exception if FASTQs don't exist for any id\n",
    "def get_fastqs(\n",
    "    path: str, # path to directory containing FASTQ files\n",
    "    fastq_file_ids: list, # FASTQ file ids needed for this run type (e.g. I1, R1, R2, etc.)\n",
    "):\n",
    "    fastq_map = dict()\n",
    "    _, bucket, key, _, _ = urllib.parse.urlsplit(path)\n",
    "    for fid in fastq_file_ids:\n",
    "        files = get_s3_objects(\n",
    "            bucket, key.lstrip(\"/\"),\n",
    "            re.compile(f\"_{fid}_\\d{{3}}.fastq.gz$\")\n",
    "        )\n",
    "        try:\n",
    "            assert files, f\"AssertionError: Missing `{fid}` archives!\"\n",
    "            fastq_map[fid] = [os.path.join(\"s3://\", bucket, str(f)) for f in files]\n",
    "        except AssertionError as err:\n",
    "            logging.warning(\"%s\\n\\t %s\", err, path)\n",
    "            return\n",
    "    return fastq_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FASTQ sample name from list of files\n",
    "# Note: FASTQ name is file name up to lane id (e.g. L001, L002, etc.)\n",
    "def get_fastqs_name(fastqs):\n",
    "    fastq_name_re = r\".*/(.*)_S\\d+_L\\d{3}_[A-Za-z]\\d_\\d{3}.fastq.gz$\"\n",
    "    fastq_names = [re.match(fastq_name_re, x)[1] for x in fastqs]\n",
    "    assert len(set(fastq_names)) == 1 # make sure all names are same\n",
    "    return fastq_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy encoder for JSON from pandas series\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from SCRIdb\n",
    "def get_s3_objects(bucket, key, pattern, full_uri=False):\n",
    "    \n",
    "    s3r = boto3.resource(\"s3\")\n",
    "    bucket_s3 = s3r.Bucket(bucket)\n",
    "    objects = []\n",
    "    for obj in bucket_s3.objects.filter(Prefix=key):\n",
    "        hit = pattern.search(obj.key)\n",
    "        if hit:\n",
    "            objects.append(obj.key)\n",
    "    if full_uri:\n",
    "        objects = [f\"s3://{bucket}/{o}\" for o in objects]\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query, user, password):\n",
    "    with connect(\n",
    "        host=\"peer-lab-db.cggxmlwgzzpw.us-east-1.rds.amazonaws.com\",\n",
    "        database=\"peer_lab_db\",\n",
    "        user=user,\n",
    "        password=password,\n",
    "    ) as connection:\n",
    "        with connection.cursor(buffered=True) as cursor:\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_species(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_species = \"peer_lab_db.species\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_species}.Species\n",
    "        FROM {table_species}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_species}.id = {table_genome_idx}.species_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sc_tech(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_sc_tech = \"peer_lab_db.sc_tech\"\n",
    "        table_genome_idx = \"peer_lab_db.genome_index\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sc_tech}.sc_Tech\n",
    "        FROM {table_sc_tech}\n",
    "        LEFT JOIN {table_genome_idx}\n",
    "        ON {table_sc_tech}.id = {table_genome_idx}.scTech_id\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_genome_idx}.id = {table_sample_data}.genomeIndex_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_sample_id(sample_name, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_sample_data}.id\n",
    "        FROM {table_sample_data}\n",
    "        WHERE {table_sample_data}.Sample=\"{sample_name}\"\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get species from database for given sample\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "def get_project_id(sample_id, user, password):\n",
    "    try:\n",
    "        table_sample_data = \"peer_lab_db.sample_data\"\n",
    "        table_project_data = \"peer_lab_db.project_data\"\n",
    "        query = f\"\"\"\n",
    "        SELECT {table_project_data}.projectName\n",
    "        FROM {table_project_data}\n",
    "        LEFT JOIN {table_sample_data}\n",
    "        ON {table_project_data}.id = {table_sample_data}.projectData_id\n",
    "        WHERE {table_sample_data}.id = {sample_id}\n",
    "        \"\"\"\n",
    "        result = execute_query(query, user, password)[0][0]\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SEQC_version(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 cp {loc}/seqc-results/seqc_log.txt -\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        version = re.match(r\".*SEQC=v(\\d+\\.\\d+\\.\\d+).*\", out)[1]\n",
    "        return version\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_prefix(loc):\n",
    "    try:\n",
    "        cmd = f\"aws s3 ls {loc}/seqc-results/\"\n",
    "        out = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True).__dict__[\"stdout\"]\n",
    "        \n",
    "        # Note: I'm expecting the aligned bam file to be in loc\n",
    "        bam_pattern = re.compile(r\"(.*)_Aligned\\.out\\.bam$\")\n",
    "        filename = list(filter(bam_pattern.match, out.split()))[0]\n",
    "        file_prefix = re.match(bam_pattern, filename)[1]\n",
    "        return file_prefix\n",
    "    except:\n",
    "        raise ValueError(f\"BAM file not found in {loc}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTQ reads/indices required for each workflow\n",
    "# Shoudl replace with JSON file\n",
    "cr_reference_map = {\n",
    "    'CellRangerArc':\n",
    "    {\n",
    "        'Human': \"https://cf.10xgenomics.com/supp/cell-arc/refdata-cellranger-arc-GRCh38-2020-A.tar.gz\",\n",
    "        'Mouse': \"https://cf.10xgenomics.com/supp/cell-arc/refdata-cellranger-arc-mm10-2020-A-2.0.0.tar.gz\",\n",
    "    },\n",
    "    'CellRangerATAC':\n",
    "    {\n",
    "        'Human': \"https://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-arc-GRCh38-2020-A-2.0.0.tar.gz\",\n",
    "        'Mouse': \"https://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-arc-mm10-2020-A-2.0.0.tar.gz\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_cr_reference(sample_id, prefix, user, password):\n",
    "    # Get species from database to decide reference\n",
    "    species = get_species(sample_id, user, password)\n",
    "    \n",
    "    # Map to reference locations\n",
    "    try:\n",
    "        return cr_reference_map[prefix][species]\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown Species: {species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bc_whitelist(sample_id):\n",
    "    # Get version from database to decide whitelist\n",
    "    sc_tech = get_sc_tech(sample_id, creds[\"user\"], creds[\"password\"])\n",
    "    \n",
    "    # Map to reference locations\n",
    "    if \"V3\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v3/flat/3M-february-2018.txt\"\n",
    "    elif \"V2\" in sc_tech:\n",
    "        return \"s3://seqc-public/barcodes/ten_x_v2/flat/737K-august-2016.txt\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Technology: {sc_tech}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(\n",
    "    workflow_path: str,\n",
    "    execp: str,\n",
    "    secrets: str,\n",
    "    inputs: str,\n",
    "    labels: str,\n",
    "    options: str,\n",
    "):\n",
    "    # change working directory to the pipeline package\n",
    "    oldwd = os.getcwd()\n",
    "    os.chdir(workflow_path)\n",
    "    \n",
    "    # execute the pipeline command\n",
    "    cmd = f\"{workflow_path}/{execp} -k {secrets} -i {inputs} -l {labels} -o {options}\"\n",
    "    var = subprocess.run(shlex.split(cmd), universal_newlines=True, capture_output=True)\n",
    "    out = var.__dict__\n",
    "    \n",
    "    # change working directory back\n",
    "    os.chdir(oldwd)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps from .wdl name (prefix) to results dirname\n",
    "results_dirs = {\n",
    "    \"TransgenesSeqc\": \"refdata-seqc\",\n",
    "    \"TransgenesCellRanger\": \"refdata-cellranger\",\n",
    "}\n",
    "\n",
    "# Maps from .wdl name (prefix) to shell script\n",
    "sh_files = {\n",
    "    \"TransgenesSeqc\": \"submit-seqc.sh\",\n",
    "    \"TransgenesCellRanger\": \"submit-cellranger.sh\",\n",
    "}\n",
    "\n",
    "# Version (CellRanger or Star) to use; Should be in database\n",
    "latest_STAR = \"2.5.3a\"\n",
    "latest_CellRanger = \"6.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Location of docker files\n",
    "common_docker_registry = \"quay.io/hisplan\"\n",
    "\n",
    "prefix = \"TransgenesCellRanger\" # Workflow to run; also .wdl filename prefix\n",
    "pipeline_type = prefix # field in *.labels.json\n",
    "output_dirname = results_dirs[prefix]\n",
    "\n",
    "# If need to add comment, put here\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of workflow-related directories and files\n",
    "path_to_cromwell_secrets = f\"{Path.home()}/.cromwell/cromwell-secrets.json\" # CHANGE THIS\n",
    "workflow_dir = f\"{Path.home()}/scing/bin/transgenes-0.0.8\" # CHANGE THIS\n",
    "exec_file = sh_files[prefix]\n",
    "config_dir = f\"{workflow_dir}/config\"\n",
    "path_to_options = f\"{workflow_dir}/Transgenes.options.aws.json\"\n",
    "\n",
    "# Other file locations\n",
    "db_credentials_path = f\"{Path.home()}/.config.json\" # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials based on SCRIdb CLI config file\n",
    "with open(db_credentials_path) as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of CSV file containing Google Forms results\n",
    "# Note: Script will build a transgene for EVERY row in CSV\n",
    "path_to_forms = f\"{Path.home()}/scing/transgene_forms/example.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/moormana/scing/transgene_forms/example.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/h4w1ldx521q4chnz86nr3188kf0lh6/T/ipykernel_76982/3706935376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get answers from forms submissions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m submissions = pd.read_csv(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpath_to_forms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0msubmissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/scing/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/moormana/scing/transgene_forms/example.csv'"
     ]
    }
   ],
   "source": [
    "# Get answers from forms submissions\n",
    "submissions = pd.read_csv(\n",
    "    path_to_forms, index_col = 3, dtype=str\n",
    ")\n",
    "submissions.index = submissions.index.rename(\"Sample\")\n",
    "submissions[\"Sample_ID\"] = pd.Series(submissions.index).apply(\n",
    "    lambda x: get_sample_id(x, creds['user'], creds['password'])\n",
    ").values\n",
    "submissions[\"Project_Name\"] = submissions[\"Sample_ID\"].apply(\n",
    "    lambda x: get_project_id(x, creds['user'], creds['password'])\n",
    ").values\n",
    "submissions[\"Parsed_Species\"] = submissions[\"Species\"].apply(parse_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum inputs and labels fields from templates\n",
    "pipeline_type = prefix.split('Transgenes')[-1].lower()\n",
    "with open(f\"{config_dir}/template.{pipeline_type}.inputs.json\") as f:\n",
    "    std_inputs_fields = list(json.load(f).keys())\n",
    "    \n",
    "with open(f\"{config_dir}/template.{pipeline_type}.labels.json\") as f:\n",
    "    std_labels_fields = list(json.load(f).keys())\n",
    "    \n",
    "# Annotate all samples with workflow inputs and labels\n",
    "inputs = pd.DataFrame(index=submissions.index, columns=std_inputs_fields,)\n",
    "labels = pd.DataFrame(index=submissions.index, columns=std_labels_fields,)\n",
    "\n",
    "# Annotate inputs\n",
    "inputs[f\"{prefix}.referenceName\"] = \\\n",
    "    submissions[\"Project_Name\"] + \"-\" + \\\n",
    "    submissions[\"Parsed_Species\"].apply(lambda x: f\"{x[1]}-Ensembl-{x[2]}\") + \"-\" \\\n",
    "    \"transgenes\"\n",
    "inputs[f\"{prefix}.genomeReferenceFasta\"] = \\\n",
    "    submissions[\"Parsed_Species\"].apply(lambda x: ref_map[x[1:]][1])\n",
    "inputs[f\"{prefix}.annotationGtf\"] = \\\n",
    "    submissions[\"Parsed_Species\"].apply(lambda x: ref_map[x[1:]][0])\n",
    "inputs[f\"{prefix}.customFastaFiles\"] = \\\n",
    "     submissions[\"AWS S3 location(s) of the FASTA sequence of your reporter genes\"].apply(lambda x: x.split(\"\\n\"))\n",
    "inputs[f\"{prefix}.ensembleIdPrefix\"] = \\\n",
    "    submissions[\"Parsed_Species\"].apply(lambda x: ensembl_map[x[0]])\n",
    "inputs[f\"{prefix}.ensembleIds\"] = submissions[\"Ensembl ID of transgene\"].apply(lambda x: x.split(\"\\n\"))\n",
    "if pipeline_type == \"TransgenesSEQC\":\n",
    "    inputs[f\"{prefix}.starVersion\"] = latest_STAR\n",
    "else:\n",
    "    inputs[f\"{prefix}.cellRangerVersion\"] = latest_CellRanger\n",
    "standard_biotypes = [\n",
    "    \"protein_coding\", \"lincRNA\", \"antisense\",\n",
    "    \"IG_V_gene\", \"IG_D_gene\", \"IG_J_gene\", \"IG_C_gene\",\n",
    "    \"TR_V_gene\", \"TR_D_gene\", \"TR_J_gene\", \"TR_C_gene\",\n",
    "]\n",
    "inputs[f\"{prefix}.biotypes\"] = inputs.iloc[:, 0].apply(lambda x: standard_biotypes)\n",
    "inputs[f\"{prefix}.dockerRegistry\"] = common_docker_registry\n",
    "\n",
    "# Annotate labels\n",
    "labels[\"pipelineType\"] = prefix\n",
    "labels[\"project\"] = submissions[\"Project_Name\"]\n",
    "labels[\"sample\"] = labels.index\n",
    "labels[\"owner\"] = creds[\"user\"]\n",
    "labels[\"destination\"] = \\\n",
    "    submissions[\"AWS S3 location where you want the newly built genome to be stored\"].str.strip(\"/\") + \\\n",
    "    \"/\" + output_dirname\n",
    "    \n",
    "labels[\"transfer\"] = \"-\"\n",
    "labels[\"comment\"] = creds[\"user\"]\n",
    "\n",
    "assert (std_inputs_fields == list(inputs.columns)) & (inputs.notna().values.all())\n",
    "assert (std_labels_fields == list(labels.columns)) & (labels.notna().values.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/h4w1ldx521q4chnz86nr3188kf0lh6/T/ipykernel_76982/966412700.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipelineType</th>\n",
       "      <th>project</th>\n",
       "      <th>sample</th>\n",
       "      <th>owner</th>\n",
       "      <th>destination</th>\n",
       "      <th>transfer</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LJ-1422_PS19</th>\n",
       "      <td>TransgenesCellRanger</td>\n",
       "      <td>3PS19_SNSEQ</td>\n",
       "      <td>LJ-1422_PS19</td>\n",
       "      <td>moormana</td>\n",
       "      <td>s3://dp-lab-data/collaborators/yuemi...</td>\n",
       "      <td>-</td>\n",
       "      <td>moormana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pipelineType      project        sample     owner  \\\n",
       "Sample                                                                    \n",
       "LJ-1422_PS19  TransgenesCellRanger  3PS19_SNSEQ  LJ-1422_PS19  moormana   \n",
       "\n",
       "                                          destination transfer   comment  \n",
       "Sample                                                                    \n",
       "LJ-1422_PS19  s3://dp-lab-data/collaborators/yuemi...        -  moormana  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e12080bcc44069808cb0af080fd381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdouts = [] # to store all outputs\n",
    "process = True\n",
    "\n",
    "with tqdm(submissions.index) as t:\n",
    "\n",
    "    for sample_name in t:\n",
    "\n",
    "        # Write inputs and labels to file\n",
    "        path_to_inputs = f\"{config_dir}/{sample_name}.inputs.json\"\n",
    "        with open(path_to_inputs, \"w\") as f_inputs:\n",
    "            json.dump(inputs.loc[sample_name].to_dict(), f_inputs, indent=4, cls=NpEncoder)\n",
    "\n",
    "        path_to_labels = f\"{config_dir}/{sample_name}.labels.json\"\n",
    "        with open(path_to_labels, \"w\") as f_labels:\n",
    "            json.dump(labels.loc[sample_name].to_dict(), f_labels, indent=4, cls=NpEncoder)\n",
    "\n",
    "        if process:\n",
    "            stdouts.append(run(\n",
    "                workflow_path = workflow_dir,\n",
    "                execp = exec_file,\n",
    "                secrets = path_to_cromwell_secrets,\n",
    "                inputs = path_to_inputs,\n",
    "                labels = path_to_labels,\n",
    "                options = path_to_options,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"6de3bcc1-8707-4047-890e-db16005688f9\",\"status\":\"Submitted\"}\n",
      "{\"id\":\"3a54f991-37b2-4c56-b447-e68d854d3246\",\"status\":\"Submitted\"}\n",
      "{\"id\":\"1964ed8b-33d6-4f5e-81b8-2eae34c1f437\",\"status\":\"Submitted\"}\n",
      "{\"id\":\"29c83f7e-4ce2-41bb-a0d6-d6143b2b53db\",\"status\":\"Submitted\"}\n",
      "{\"id\":\"3fed61b5-7d00-48e8-bb59-8f243a6a6702\",\"status\":\"Submitted\"}\n",
      "{\"id\":\"8e1b696e-53b8-4563-8a01-9f92d0941a33\",\"status\":\"Submitted\"}\n"
     ]
    }
   ],
   "source": [
    "configs = !ls configs/\n",
    "pattern = re.compile(r'3.*CPL.*')\n",
    "configs = np.sort(list(filter(pattern.match, configs)))\n",
    "l1 = configs[:-1:2]\n",
    "l2 = configs[1::2]\n",
    "for inputs, labels in zip(l1, l2):\n",
    "    !bash submit-cellplex.sh -i configs/$inputs -l configs/$labels -k ../../../.cromwell/cromwell-secrets.json -o Sharp.options.aws.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
